{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"markdown","metadata":{"id":"lDJIV2EVBuFZ"},"source":["# Hidden Markov Models\n"]},{"cell_type":"markdown","metadata":{"id":"_rWFkdjYOlk8"},"source":["이 노트북은 순차 데이터에 대한 간단한 모델인 HMM(Hidden Markov Model)을 소개합니다.\n","\n","다음 내용을 다룹니다.:\n","- HMM이란 무엇이며 언제 사용하고 싶은지\n","- HMM의 \"3가지 문제\"\n","- PyTorch에서 HMM을 구현하는 방법.\n","\n","(이 노트북의 코드는 https://github.com/lorenlugosch/pytorch_HMM에서도 찾을 수 있습니다.)"]},{"cell_type":"markdown","metadata":{"id":"efPPcGy0gP6H"},"source":["가상 시나리오\n","------\n","\n","HMM 사용에 동기를 부여하려면 여행을 많이 하는 친구가 있다고 상상해 보십시오. 제트기 친구는 매일 자신이 있는 도시에서 셀카를 보내 당신을 부러워하게 만듭니다."]},{"cell_type":"markdown","metadata":{"id":"Cs3z7pnVib9g"},"source":["<center>\n","\n","![Diagram of a traveling friend sending selfies](https://github.com/lorenlugosch/pytorch_HMM/blob/master/img/selfies.png?raw=true)\n","</center>\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hTPNK3IjirDA"},"source":["셀카만 보고 매일 그 친구가 어느 도시에 있는지 추측하는 방법은 무엇입니까?\n","\n","셀카에 에펠탑과 같이 정말 눈에 띄는 랜드마크가 포함되어 있으면 사진을 찍은 위치를 쉽게 파악할 수 있습니다. 그렇지 않으면 도시를 유추하는 것이 훨씬 더 어려울 것입니다.\n","\n","그러나 우리에게는 도움이 될 단서가 있습니다. 친구가 매일 있는 도시는 완전히 무작위가 아닙니다. 예를 들어 친구는 새로운 도시로 날아가기 전에 관광을 위해 며칠 동안 같은 도시에 머물 것입니다."]},{"cell_type":"markdown","metadata":{"id":"k4g7IG7CBx-Y"},"source":["## The HMM setup\n","\n","친구가 도시를 오가며 셀카를 보내는 가상 시나리오는 HMM을 사용하여 모델링할 수 있습니다.\n"]},{"cell_type":"markdown","metadata":{"id":"NpwgbDTnRzRa"},"source":["HMM은 주어진 시간에 특정 상태에 있는 시스템을 모델링하고 해당 상태에 따라 출력을 생성합니다.\n","\n","각 타임스텝 또는 클록 틱에서 시스템은 무작위로 새 상태를 결정하고 해당 상태로 이동합니다. 그런 다음 시스템은 무작위로 관찰을 생성합니다. 상태는 \"숨겨져\" 있으므로 관찰할 수 없습니다. (도시/셀카 비유에서 미지의 도시는 숨겨진 상태가 되고 셀카는 관찰 대상이 됩니다.)\n","\n","상태의 시퀀스를 $\\mathbf{z} = \\{z_1, z_2, \\dots, z_T \\}$로 나타내자. 여기서 각 상태는 유한한 $N$ 상태 집합 중 하나이고 관찰 시퀀스는 $로 나타냅니다. \\mathbf{x} = \\{x_1, x_2, \\dots, x_T\\}$. 관측값은 문자처럼 불연속적이거나 오디오 프레임처럼 실제 값일 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"uV5fAhEQDAcJ"},"source":["<center>\n","\n","![Diagram of an HMM for three timesteps](https://github.com/lorenlugosch/pytorch_HMM/blob/master/img/hmm.png?raw=true)\n","</center>"]},{"cell_type":"markdown","metadata":{"id":"vMPrA6Uv-u-K"},"source":["HMM은 두 가지 주요 가정을 합니다.\n","- **가정 1:** 시간 $t$의 상태는 이전 시간 $t-1$의 상태에만 의존합니다.\n","- **가정 2:** $t$ 시간의 출력은 $t$ 시간의 상태에만 의존합니다.\n","\n","이 두 가지 가정을 통해 우리가 관심을 가질 수 있는 특정 수량을 효율적으로 계산할 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"mRNhSK7LgEIS"},"source":["## HMM의 구성 요소\n","HMM에는 세 가지 학습 가능한 매개변수 세트가 있습니다.\n","  \n"]},{"cell_type":"markdown","metadata":{"id":"7Pu3zm77vXwp"},"source":["- **전환 모델**은 정사각형 행렬 $A$이며 $A_{s, s'}$는 $p(z_t = s|z_{t-1} = s')$, 점프 확률을 나타냅니다. 상태 $s'$에서 상태 $s$로.\n","\n","- **방출 모델** $b_s(x_t)$는 시스템이 $s$ 상태에 있을 때 $x_t$를 생성할 확률인 $p(x_t|z_t = s)$를 알려줍니다. 이 노트북에서 사용할 불연속 관측의 경우 방출 모델은 각 상태에 대해 하나의 행과 각 관측에 대해 하나의 열이 있는 조회 테이블일 뿐입니다. 실제 값 관측의 경우 방출 모델을 구현하기 위해 가우시안 혼합 모델 또는 신경망을 사용하는 것이 일반적입니다.\n","\n","- **상태 사전**은 $s$ 상태에서 시작할 확률인 $p(z_1 = s)$를 알려줍니다. 우리는 $\\pi$를 사용하여 상태 사전 벡터를 나타내므로 $\\pi_s$는 상태 $s$에 대한 사전 상태입니다.\n","\n","PyTorch에서 HMM 클래스를 프로그래밍해 봅시다."]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","\n","a = np.array([[1.,1.],\n","              [2.,2.]])\n","b = torch.tensor(a)\n","print(b)\n","c = torch.nn.Parameter(b)\n","print(c)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dGj1c_0dLF3B","executionInfo":{"status":"ok","timestamp":1672927799539,"user_tz":-540,"elapsed":2799,"user":{"displayName":"김정인","userId":"08669711361714769540"}},"outputId":"343f9f26-b594-4329-9fd1-5c8e50a1ed3b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 1.],\n","        [2., 2.]], dtype=torch.float64)\n","Parameter containing:\n","tensor([[1., 1.],\n","        [2., 2.]], dtype=torch.float64, requires_grad=True)\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","\n","a = torch.randn(2,2)\n","b = torch.nn.Parameter(a)\n","print(b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gHZ31TC5MDza","executionInfo":{"status":"ok","timestamp":1672927799539,"user_tz":-540,"elapsed":16,"user":{"displayName":"김정인","userId":"08669711361714769540"}},"outputId":"64dcd30f-fbaf-41d7-99f8-6cc8a3f60cd1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Parameter containing:\n","tensor([[-0.2913,  0.4814],\n","        [ 0.2206, -0.6649]], requires_grad=True)\n"]}]},{"cell_type":"code","metadata":{"id":"aZbW6Pj0og7K","executionInfo":{"status":"ok","timestamp":1672927799539,"user_tz":-540,"elapsed":14,"user":{"displayName":"김정인","userId":"08669711361714769540"}}},"source":["import torch\n","import numpy as np\n","\n","class HMM(torch.nn.Module):\n","  \"\"\"\n","  Hidden Markov Model with discrete observations.\n","  \"\"\"\n","  def __init__(self, M, N):\n","    super(HMM, self).__init__()\n","    self.M = M # number of possible observations\n","    self.N = N # number of states\n","\n","    # A\n","    self.transition_model = TransitionModel(self.N)\n","\n","    # b(x_t)\n","    self.emission_model = EmissionModel(self.N,self.M)\n","\n","    # pi\n","    self.unnormalized_state_priors = torch.nn.Parameter(torch.randn(self.N))\n","\n","    # use the GPU\n","    self.is_cuda = torch.cuda.is_available()\n","    if self.is_cuda: self.cuda()\n","\n","class TransitionModel(torch.nn.Module):\n","  def __init__(self, N):\n","    super(TransitionModel, self).__init__()\n","    self.N = N\n","    self.unnormalized_transition_matrix = torch.nn.Parameter(torch.randn(N,N))\n","\n","class EmissionModel(torch.nn.Module):\n","  def __init__(self, N, M):\n","    super(EmissionModel, self).__init__()\n","    self.N = N\n","    self.M = M\n","    self.unnormalized_emission_matrix = torch.nn.Parameter(torch.randn(N,M))"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eom3ueYtpXGo"},"source":["HMM에서 샘플링하기 위해 상태 이전 분포에서 임의의 초기 상태를 선택하여 시작합니다.\n","\n","그런 다음 방출 분포에서 출력을 샘플링하고 전이 분포에서 전이를 샘플링하고 반복합니다.\n","\n","(정규화되지 않은 모델 파라미터를 softmax 함수를 통해 전달하여 확률로 만듭니다.)\n"]},{"cell_type":"code","source":["a = torch.tensor([1.,2.,3.,4.,5.])\n","b = torch.nn.functional.softmax(a, dim=0)\n","print(b, b.sum())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"--ExFiAE545X","executionInfo":{"status":"ok","timestamp":1672927799540,"user_tz":-540,"elapsed":15,"user":{"displayName":"김정인","userId":"08669711361714769540"}},"outputId":"91b5943b-8555-43e6-b9a0-afe1b6be8acd"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.0117, 0.0317, 0.0861, 0.2341, 0.6364]) tensor(1.)\n"]}]},{"cell_type":"code","source":["a = torch.tensor([[1.,2.,3.,4.],\n","                  [1.,2.,3.,4.],\n","                  [1.,2.,3.,-np.inf]])\n","b = torch.nn.functional.softmax(a, dim=1)\n","print(b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JSy8Maur7KCJ","executionInfo":{"status":"ok","timestamp":1672927799540,"user_tz":-540,"elapsed":13,"user":{"displayName":"김정인","userId":"08669711361714769540"}},"outputId":"0b01a6dd-ca29-4209-ecc2-d1939ea4466b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.0321, 0.0871, 0.2369, 0.6439],\n","        [0.0321, 0.0871, 0.2369, 0.6439],\n","        [0.0900, 0.2447, 0.6652, 0.0000]])\n"]}]},{"cell_type":"code","source":["a = torch.tensor([[1.,2.,3.,4.],\n","                  [1.,2.,3.,4.],\n","                  [1.,2.,3.,4.]])\n","b = torch.nn.functional.softmax(a, dim=0)\n","print(b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J-RqI5xkOjsD","executionInfo":{"status":"ok","timestamp":1672927799540,"user_tz":-540,"elapsed":12,"user":{"displayName":"김정인","userId":"08669711361714769540"}},"outputId":"e8375752-31c1-4eb1-a98c-ed3a14a8d3fc"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.3333, 0.3333, 0.3333, 0.3333],\n","        [0.3333, 0.3333, 0.3333, 0.3333],\n","        [0.3333, 0.3333, 0.3333, 0.3333]])\n"]}]},{"cell_type":"code","source":["m = torch.distributions.categorical.Categorical(torch.tensor([ 0.9, 0.1, 0.0, 0.0 ]))\n","m.sample().item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8MfzTzmCPILr","executionInfo":{"status":"ok","timestamp":1672927799540,"user_tz":-540,"elapsed":11,"user":{"displayName":"김정인","userId":"08669711361714769540"}},"outputId":"898ed8d2-648b-4bc1-d6c7-92dd78e82c61"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["a = torch.tensor([ [0.8, 0.3], \n","                   [0.2, 0.7] ])\n","print(a[:,1])\n","m = torch.distributions.categorical.Categorical(a[:,1])\n","m.sample().item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oar-sUoTQhSc","executionInfo":{"status":"ok","timestamp":1672927799541,"user_tz":-540,"elapsed":11,"user":{"displayName":"김정인","userId":"08669711361714769540"}},"outputId":"80fcf3ff-8759-4687-f236-7a4c46a04003"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.3000, 0.7000])\n"]},{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"BpgkwNyVwmyM","executionInfo":{"status":"ok","timestamp":1672927799541,"user_tz":-540,"elapsed":10,"user":{"displayName":"김정인","userId":"08669711361714769540"}}},"source":["def sample(self, T=10):\n","  state_priors = torch.nn.functional.softmax(self.unnormalized_state_priors, dim=0)\n","  transition_matrix = torch.nn.functional.softmax(self.transition_model.unnormalized_transition_matrix, dim=0)\n","  emission_matrix = torch.nn.functional.softmax(self.emission_model.unnormalized_emission_matrix, dim=1)\n","\n","  # sample initial state\n","  z_t = torch.distributions.categorical.Categorical(state_priors).sample().item()\n","  z = []; x = []\n","  z.append(z_t)\n","  for t in range(0,T):\n","    # sample emission\n","    x_t = torch.distributions.categorical.Categorical(emission_matrix[z_t]).sample().item()\n","    x.append(x_t)\n","\n","    # sample transition\n","    z_t = torch.distributions.categorical.Categorical(transition_matrix[:,z_t]).sample().item()\n","    if t < T-1: z.append(z_t)\n","\n","  return x, z\n","\n","# Add the sampling method to our HMM class\n","HMM.sample = sample"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ohsdYScawkRG"},"source":["가짜 단어를 생성하기 위해 HMM을 하드 코딩해 봅시다. (문자열 인코딩 및 디코딩을 위한 몇 가지 도우미 함수도 추가합니다.)\n","\n","우리는 시스템이 모음을 생성하기 위한 하나의 상태와 자음을 생성하기 위한 하나의 상태를 가지고 있고, 전환 행렬이 대각선에 0을 가지고 있다고 가정할 것입니다. 한 단계; 전환해야합니다.\n","\n","softmax를 통해 전이 행렬을 전달하므로 0을 얻기 위해 비정규화 매개변수 값을 $-\\infty$로 설정합니다."]},{"cell_type":"code","source":["import string\n","alphabet = string.ascii_lowercase\n","print(alphabet, len(alphabet))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rQUh_4NpKEIg","executionInfo":{"status":"ok","timestamp":1672927799541,"user_tz":-540,"elapsed":9,"user":{"displayName":"김정인","userId":"08669711361714769540"}},"outputId":"fc03e6bf-2b2f-4b8a-d4f6-c60cfd37314c"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["abcdefghijklmnopqrstuvwxyz 26\n"]}]},{"cell_type":"code","source":["print(alphabet.index('a'))\n","print(alphabet[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CfvE9lmym5x4","executionInfo":{"status":"ok","timestamp":1672927799542,"user_tz":-540,"elapsed":9,"user":{"displayName":"김정인","userId":"08669711361714769540"}},"outputId":"1808bb09-d246-4b26-84ee-25840ccb3f91"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","a\n"]}]},{"cell_type":"code","source":["a = torch.tensor([alphabet.index(letter) for letter in \"aeiou\"])\n","print(a)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oeCDzK7XotQH","executionInfo":{"status":"ok","timestamp":1672927799542,"user_tz":-540,"elapsed":8,"user":{"displayName":"김정인","userId":"08669711361714769540"}},"outputId":"cd001054-6438-4989-b222-9944e6214159"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 0,  4,  8, 14, 20])\n"]}]},{"cell_type":"code","source":["b = torch.tensor([alphabet.index(letter) for letter in \"bcdfghjklmnpqrstvwxyz\"])\n","print(b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ajQghKVQpKQ2","executionInfo":{"status":"ok","timestamp":1672927799542,"user_tz":-540,"elapsed":7,"user":{"displayName":"김정인","userId":"08669711361714769540"}},"outputId":"dc1cf2ef-29d0-44ae-f173-99be33feef64"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 1,  2,  3,  5,  6,  7,  9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22,\n","        23, 24, 25])\n"]}]},{"cell_type":"code","metadata":{"id":"eyR7yv_3sBG3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dbbf658d-0870-4097-962d-c8679d3792e2","executionInfo":{"status":"ok","timestamp":1672927804518,"user_tz":-540,"elapsed":4982,"user":{"displayName":"김정인","userId":"08669711361714769540"}}},"source":["import string\n","alphabet = string.ascii_lowercase\n","\n","def encode(s):\n","  \"\"\"\n","  Convert a string into a list of integers\n","  \"\"\"\n","  x = [alphabet.index(ss) for ss in s]\n","  return x\n","\n","def decode(x):\n","  \"\"\"\n","  Convert list of ints to string\n","  \"\"\"\n","  s = \"\".join([alphabet[xx] for xx in x])\n","  return s\n","\n","# Initialize the model\n","model = HMM(M=len(alphabet), N=2) \n","\n","# for p in model.parameters():\n","#     print(p)\n","# Hard-wiring the parameters!\n","# Let state 0 = consonant, state 1 = vowel\n","for p in model.parameters():\n","    p.requires_grad = False # needed to do lines below\n","model.unnormalized_state_priors[0] = 0.    # Let's start with a consonant more frequently\n","model.unnormalized_state_priors[1] = -0.5\n","print(\"State priors:\", torch.nn.functional.softmax(model.unnormalized_state_priors, dim=0))\n","\n","# In state 0, only allow consonants; in state 1, only allow vowels\n","vowel_indices = torch.tensor([alphabet.index(letter) for letter in \"aeiou\"])\n","consonant_indices = torch.tensor([alphabet.index(letter) for letter in \"bcdfghjklmnpqrstvwxyz\"])\n","model.emission_model.unnormalized_emission_matrix[0, vowel_indices] = -np.inf\n","model.emission_model.unnormalized_emission_matrix[1, consonant_indices] = -np.inf \n","print(\"Emission matrix:\", torch.nn.functional.softmax(model.emission_model.unnormalized_emission_matrix, dim=1))\n","\n","# Only allow vowel -> consonant and consonant -> vowel\n","\n","model.transition_model.unnormalized_transition_matrix[0,0] = -np.inf  # consonant -> consonant\n","model.transition_model.unnormalized_transition_matrix[0,1] = 0.       # vowel -> consonant\n","model.transition_model.unnormalized_transition_matrix[1,0] = 0.       # consonant -> vowel\n","model.transition_model.unnormalized_transition_matrix[1,1] = -np.inf  # vowel -> vowel\n","print(\"Transition matrix:\", torch.nn.functional.softmax(model.transition_model.unnormalized_transition_matrix, dim=0))\n","\n"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["State priors: tensor([0.6225, 0.3775], device='cuda:0')\n","Emission matrix: tensor([[0.0000, 0.0441, 0.0333, 0.0553, 0.0000, 0.0320, 0.0787, 0.0235, 0.0000,\n","         0.1166, 0.0154, 0.0087, 0.0333, 0.0160, 0.0000, 0.0457, 0.0311, 0.0315,\n","         0.0582, 0.0178, 0.0000, 0.1285, 0.0220, 0.1076, 0.0240, 0.0769],\n","        [0.1393, 0.0000, 0.0000, 0.0000, 0.1621, 0.0000, 0.0000, 0.0000, 0.0331,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3359, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.3296, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0')\n","Transition matrix: tensor([[0., 1.],\n","        [1., 0.]], device='cuda:0')\n"]}]},{"cell_type":"markdown","metadata":{"id":"KFaYq8jDttmi"},"source":["하드 코딩된 모델에서 샘플링을 시도하십시오.\n"]},{"cell_type":"code","metadata":{"id":"8latFMD7ua0X","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f18dc1ee-2340-4a76-d70a-150370d0d52c","executionInfo":{"status":"ok","timestamp":1672927804518,"user_tz":-540,"elapsed":8,"user":{"displayName":"김정인","userId":"08669711361714769540"}}},"source":["# Sample some outputs\n","for _ in range(4):\n","  sampled_x, sampled_z = model.sample(T=5)\n","  print(\"x:\", decode(sampled_x))\n","  print(\"z:\", sampled_z)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["x: omuxu\n","z: [1, 0, 1, 0, 1]\n","x: agavu\n","z: [1, 0, 1, 0, 1]\n","x: xugug\n","z: [0, 1, 0, 1, 0]\n","x: yegor\n","z: [0, 1, 0, 1, 0]\n"]}]},{"cell_type":"markdown","metadata":{"id":"hKzlTlfRgZod"},"source":["## 세 가지 문제\n","\n","HMM에 대한 [클래식 자습서](https://www.cs.cmu.edu/~cga/behavior/rabiner1.pdf)에서 Lawrence Rabiner는 HMM을 효과적으로 사용하기 전에 해결해야 하는 \"세 가지 문제\"를 설명합니다. . 그들은:\n","- 문제 1: $p(\\mathbf{x})$를 어떻게 효율적으로 계산합니까?\n","- 문제 2: 데이터를 생성했을 가능성이 가장 높은 상태 시퀀스 $\\mathbf{z}$를 어떻게 찾습니까?\n","- 문제 3: 모델을 어떻게 교육합니까?\n","\n","노트북의 나머지 부분에서는 각 문제를 해결하고 PyTorch에서 솔루션을 구현하는 방법을 살펴보겠습니다."]},{"cell_type":"markdown","metadata":{"id":"v_RfIAnmN2RZ"},"source":["### 문제 1: $p(\\mathbf{x})$를 어떻게 계산합니까?"]},{"cell_type":"markdown","metadata":{"id":"Z3zUUYH0giKV"},"source":["#### *왜?*\n","$p(\\mathbf{x})$ 컴퓨팅에 관심을 갖는 이유는 무엇입니까? 두 가지 이유가 있습니다.\n","* 두 개의 HMM $\\theta_1$ 및 $\\theta_2$가 주어지면 각 모델 $p_{\\theta_1}(\\mathbf{x})$ 및 $p_{\\theta_2}(\\mathbf{x})$에서 데이터의 가능성을 계산할 수 있습니다.     \n","둘중 데이터에 더 적합한 모델을 결정합니다.\n","\n","   (예를 들어, 영어 음성에 대한 HMM과 프랑스어 음성에 대한 HMM이 주어지면 각 모델에 대한 가능성을 계산하고 그 사람이 영어를 말하는지 프랑스어를 말하는지 추론할 가능성이 더 높은 모델을 선택할 수 있습니다.)\n","* 나중에 살펴보겠지만 $p(\\mathbf{x})$를 계산할 수 있으면 모델을 훈련할 수 있습니다.\n","\n","#### *어떻게?*\n","우리가 $p(\\mathbf{x})$를 원한다고 가정하면 어떻게 계산할까요?\n","\n","우리는 $\\mathbf{z}$ 상태의 일부 시퀀스를 방문하고 방출 분포 $p(x_t|z_t)$에서 각 $z_t$에 대한 출력 $x_t$를 선택하여 데이터가 생성되었다고 가정했습니다. 따라서 $\\mathbf{z}$를 안다면 $\\mathbf{x}$의 확률은 다음과 같이 계산할 수 있습니다.\n","\n","$$p(\\mathbf{x}|\\mathbf{z}) = \\prod_{t} p(x_t|z_t) p(z_t|z_{t-1})$$\n","\n","그러나 우리는 $\\mathbf{z}$를 모릅니다. 숨겨져 있습니다. 그러나 우리는 우리가 관찰한 것과는 별개로 주어진 $\\mathbf{z}$의 확률을 알고 있습니다. 따라서 다음과 같이 $\\mathbf{z}$에 대한 다양한 가능성을 합산하여 $\\mathbf{x}$의 확률을 얻을 수 있습니다.\n","\n","$$p(\\mathbf{x}) = \\sum_{\\mathbf{z}} p(\\mathbf{x}|\\mathbf{z}) p(\\mathbf{z}) = \\sum_{\\mathbf{z }} \\prod_{t} p(x_t|z_t) p(z_t|z_{t-1})$$\n","\n","문제는 이 합계를 직접 계산하려면 $N^T$ 항을 계산해야 한다는 것입니다. 이것은 매우 짧은 시퀀스 외에는 불가능합니다. 예를 들어 시퀀스의 길이가 $T=100$이고 가능한 상태가 $N=2$라고 가정해 보겠습니다. 그런 다음 $N^T = 2^{100} \\approx 10^{30}$ 다른 가능한 상태 시퀀스를 확인해야 합니다.\n","\n","모든 $N^T$ 항을 명시적으로 계산할 필요가 없는 $p(\\mathbf{x})$를 계산하는 방법이 필요합니다. 이를 위해 순방향 알고리즘을 사용합니다."]},{"cell_type":"markdown","metadata":{"id":"DrH0YdUAhS6J"},"source":["________\n","\n","<u><b>The Forward Algorithm</b></u>\n","\n","> for $s=1 \\rightarrow N$:\\\n","> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\alpha_{s,1} := b_s(x_1) \\cdot \\pi_s$ \n","> \n","> for $t = 2 \\rightarrow T$:\\\n","> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for $s = 1 \\rightarrow N$:\\\n","> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","> $\\alpha_{s,t} := b_s(x_t) \\cdot \\underset{s'}{\\sum} A_{s, s'} \\cdot \\alpha_{s',t-1} $\n","> \n","> $p(\\mathbf{x}) := \\underset{s}{\\sum} \\alpha_{s,T}$\\\n","> return $p(\\mathbf{x})$\n","________\n"]},{"cell_type":"markdown","metadata":{"id":"bAdpwRiMn8Vn"},"source":["순방향 알고리즘은 가능한 모든 $N^T$ 상태 시퀀스를 열거하는 것보다 훨씬 빠릅니다. 각 단계는 대부분 순방향 변수의 벡터에 전이 행렬을 곱하기 때문에 실행하는 데 $O(N^2T)$ 작업만 필요합니다. (그리고 전환 행렬이 희박한 경우 매우 자주 복잡성을 훨씬 더 줄일 수 있습니다.)\n","\n","위에 제시된 순방향 알고리즘에는 한 가지 실질적인 문제가 있습니다. 확률은 항상 0과 1 사이이기 때문에 작은 숫자의 긴 체인을 곱하기 때문에 언더플로가 발생하기 쉽습니다. 대신 로그 도메인에서 모든 작업을 수행하겠습니다. 로그 도메인에서 곱셈은 합이 되고, 합은 [logsumexp](https://lorenlugosch.github.io/posts/2020/06/logsumexp/)가 됩니다."]},{"cell_type":"markdown","metadata":{"id":"FZ8VsLFxA3iT"},"source":["________\n","\n","<u><b>The Forward Algorithm (Log Domain)</b></u>\n","\n","> for $s=1 \\rightarrow N$:\\\n","> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\text{log }\\alpha_{s,1} := \\text{log }b_s(x_1) + \\text{log }\\pi_s$ \n","> \n","> for $t = 2 \\rightarrow T$:\\\n","> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for $s = 1 \\rightarrow N$:\\\n","> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","> $\\text{log }\\alpha_{s,t} := \\text{log }b_s(x_t) +  \\underset{s'}{\\text{logsumexp}} \\left( \\text{log }A_{s, s'} + \\text{log }\\alpha_{s',t-1} \\right)$\n","> \n","> $\\text{log }p(\\mathbf{x}) := \\underset{s}{\\text{logsumexp}} \\left( \\text{log }\\alpha_{s,T} \\right)$\\\n","> return $\\text{log }p(\\mathbf{x})$\n","________"]},{"cell_type":"markdown","metadata":{"id":"g55ik6ZCEiJU"},"source":["이제 정방향 알고리즘의 수치적으로 안정적인 버전이 있으므로 PyTorch에서 구현해 보겠습니다."]},{"cell_type":"code","source":["a = torch.tensor([1,2,3])\n","print(a.max())\n","b = torch.logsumexp(a, dim=0)\n","print(b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v4doWAV8vLbb","executionInfo":{"status":"ok","timestamp":1672927804518,"user_tz":-540,"elapsed":5,"user":{"displayName":"김정인","userId":"08669711361714769540"}},"outputId":"da52e2f9-2145-4315-d60b-c4097cb39ded"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(3)\n","tensor(3.4076)\n"]}]},{"cell_type":"code","source":["a = np.array([[1,2,3],\n","              [4,5,6]])\n","\n","# a[0].shape\n","# a[:,2]\n","print(a[:,[2]])                 # (2,1)\n","print(a[:,[2]].transpose(1,0))  # (1,2)   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eCioHkXlhBs7","executionInfo":{"status":"ok","timestamp":1672932034868,"user_tz":-540,"elapsed":298,"user":{"displayName":"김정인","userId":"08669711361714769540"}},"outputId":"17eff6d5-d8e4-4269-b7c2-5e78fcb3cece"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["[[3]\n"," [6]]\n","[[3 6]]\n"]}]},{"cell_type":"code","source":["a = torch.tensor([[1,2,3],\n","                  [4,5,6]])\n","\n","# a[0].shape\n","# a[:,2]\n","print(a[:,[2]])                 # (2,1)\n","print(a[:,[2]].transpose(1,0))  # (1,2)     "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FtwGhYkjfcuh","executionInfo":{"status":"ok","timestamp":1672932023187,"user_tz":-540,"elapsed":300,"user":{"displayName":"김정인","userId":"08669711361714769540"}},"outputId":"2b576f39-993a-45ab-a69b-340a32dfaf4e"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[3],\n","        [6]])\n","tensor([[3, 6]])\n"]}]},{"cell_type":"code","metadata":{"id":"3CMdK1EfE1SJ","executionInfo":{"status":"ok","timestamp":1672941513396,"user_tz":-540,"elapsed":282,"user":{"displayName":"김정인","userId":"08669711361714769540"}}},"source":["def HMM_forward(self, x, T):\n","  \"\"\"\n","  x : IntTensor of shape (batch size, T_max)\n","  T : IntTensor of shape (batch size)\n","\n","  Compute log p(x) for each example in the batch.\n","  T = length of each example\n","  \"\"\"\n","  if self.is_cuda:\n","  \tx = x.cuda()\n","  \tT = T.cuda()\n","\n","  batch_size = x.shape[0]; T_max = x.shape[1]\n","  log_state_priors = torch.nn.functional.log_softmax(self.unnormalized_state_priors, dim=0)\n","#   print(log_state_priors)\n","  log_alpha = torch.zeros(batch_size, T_max, self.N)\n","#   print(log_alpha.shape)\n","  if self.is_cuda: log_alpha = log_alpha.cuda()\n","\n","  log_alpha[:, 0, :] = self.emission_model(x[:,0]) + log_state_priors\n","#   print(log_alpha)\n","  for t in range(1, T_max):\n","    log_alpha[:, t, :] = self.emission_model(x[:,t]) + self.transition_model(log_alpha[:, t-1, :])\n","    # print(log_alpha)\n","\n","#   print(log_alpha)\n","  # Select the sum for the final timestep (each x may have different length).\n","  log_sums = log_alpha.logsumexp(dim=2)\n","#   print(\"log_sums\", log_sums)\n","  log_probs = torch.gather(log_sums, 1, T.view(-1,1) - 1)\n","  return log_probs\n","\n","def emission_model_forward(self, x_t):\n","#   print(\"emission_model_forward\", x_t)\n","  log_emission_matrix = torch.nn.functional.log_softmax(self.unnormalized_emission_matrix, dim=1)\n","#   print(log_emission_matrix)\n","  out = log_emission_matrix[:, x_t].transpose(1,0)\n","  return out\n","\n","def transition_model_forward(self, log_alpha):\n","  \"\"\"\n","  log_alpha : Tensor of shape (batch size, N)\n","  Multiply previous timestep's alphas by transition matrix (in log domain)\n","  \"\"\"\n","  log_transition_matrix = torch.nn.functional.log_softmax(self.unnormalized_transition_matrix, dim=0)\n","#   print(\"log_transition_matrix\", log_transition_matrix)\n","  # Matrix multiplication in the log domain\n","  out = log_domain_matmul(log_transition_matrix, log_alpha.transpose(0,1)).transpose(0,1)\n","  return out\n","\n","def log_domain_matmul(log_A, log_B):\n","\t\"\"\"\n","\tlog_A : m x n\n","\tlog_B : n x p\n","\toutput : m x p matrix\n","\n","\tNormally, a matrix multiplication\n","\tcomputes out_{i,j} = sum_k A_{i,k} x B_{k,j}\n","\n","\tA log domain matrix multiplication\n","\tcomputes out_{i,j} = logsumexp_k log_A_{i,k} + log_B_{k,j}\n","\t\"\"\"\n","\tm = log_A.shape[0]\n","\tn = log_A.shape[1]\n","\tp = log_B.shape[1]\n","\n","\t# log_A_expanded = torch.stack([log_A] * p, dim=2)\n","\t# log_B_expanded = torch.stack([log_B] * m, dim=0)\n","    # fix for PyTorch > 1.5 by egaznep on Github:\n","\tlog_A_expanded = torch.reshape(log_A, (m,n,1))\n","\tlog_B_expanded = torch.reshape(log_B, (1,n,p))\n","\n","\telementwise_sum = log_A_expanded + log_B_expanded\n","\tout = torch.logsumexp(elementwise_sum, dim=1)\n","\n","\treturn out\n","\n","TransitionModel.forward = transition_model_forward\n","EmissionModel.forward = emission_model_forward\n","HMM.forward = HMM_forward"],"execution_count":102,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y-fNnZfqGb1m"},"source":["이전의 모음/자음 모델에서 순방향 알고리즘을 실행해 보세요."]},{"cell_type":"code","source":["encode(\"cat\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0cQSHw_NxPzc","executionInfo":{"status":"ok","timestamp":1672934640812,"user_tz":-540,"elapsed":268,"user":{"displayName":"김정인","userId":"08669711361714769540"}},"outputId":"c9db49e6-6f03-47a4-965c-a05724a4cb06"},"execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[2, 0, 19]"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["x = torch.stack( [torch.tensor(encode(\"cat\"))] )\n","print(x)\n","T = torch.tensor([3])\n","# print(T)\n","print(model.forward(x, T))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LApgv-1OYk13","executionInfo":{"status":"ok","timestamp":1672934641577,"user_tz":-540,"elapsed":2,"user":{"displayName":"김정인","userId":"08669711361714769540"}},"outputId":"8dd9401a-3fb0-46e6-b2a6-cecc79294af1"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 2,  0, 19]])\n","tensor([-0.4741, -0.9741], device='cuda:0')\n","emission_model_forward tensor([2], device='cuda:0')\n","tensor([[   -inf, -3.1207, -3.4031, -2.8951,    -inf, -3.4414, -2.5423, -3.7510,\n","            -inf, -2.1494, -4.1715, -4.7487, -3.4030, -4.1364,    -inf, -3.0860,\n","         -3.4701, -3.4584, -2.8435, -4.0296,    -inf, -2.0517, -3.8177, -2.2294,\n","         -3.7313, -2.5654],\n","        [-1.9711,    -inf,    -inf,    -inf, -1.8195,    -inf,    -inf,    -inf,\n","         -3.4084,    -inf,    -inf,    -inf,    -inf,    -inf, -1.0908,    -inf,\n","            -inf,    -inf,    -inf,    -inf, -1.1100,    -inf,    -inf,    -inf,\n","            -inf,    -inf]], device='cuda:0')\n","tensor([[[-3.8771,    -inf],\n","         [ 0.0000,  0.0000],\n","         [ 0.0000,  0.0000]]], device='cuda:0')\n","emission_model_forward tensor([0], device='cuda:0')\n","tensor([[   -inf, -3.1207, -3.4031, -2.8951,    -inf, -3.4414, -2.5423, -3.7510,\n","            -inf, -2.1494, -4.1715, -4.7487, -3.4030, -4.1364,    -inf, -3.0860,\n","         -3.4701, -3.4584, -2.8435, -4.0296,    -inf, -2.0517, -3.8177, -2.2294,\n","         -3.7313, -2.5654],\n","        [-1.9711,    -inf,    -inf,    -inf, -1.8195,    -inf,    -inf,    -inf,\n","         -3.4084,    -inf,    -inf,    -inf,    -inf,    -inf, -1.0908,    -inf,\n","            -inf,    -inf,    -inf,    -inf, -1.1100,    -inf,    -inf,    -inf,\n","            -inf,    -inf]], device='cuda:0')\n","log_transition_matrix tensor([[-inf, 0.],\n","        [0., -inf]], device='cuda:0')\n","tensor([[[-3.8771,    -inf],\n","         [   -inf, -5.8482],\n","         [ 0.0000,  0.0000]]], device='cuda:0')\n","emission_model_forward tensor([19], device='cuda:0')\n","tensor([[   -inf, -3.1207, -3.4031, -2.8951,    -inf, -3.4414, -2.5423, -3.7510,\n","            -inf, -2.1494, -4.1715, -4.7487, -3.4030, -4.1364,    -inf, -3.0860,\n","         -3.4701, -3.4584, -2.8435, -4.0296,    -inf, -2.0517, -3.8177, -2.2294,\n","         -3.7313, -2.5654],\n","        [-1.9711,    -inf,    -inf,    -inf, -1.8195,    -inf,    -inf,    -inf,\n","         -3.4084,    -inf,    -inf,    -inf,    -inf,    -inf, -1.0908,    -inf,\n","            -inf,    -inf,    -inf,    -inf, -1.1100,    -inf,    -inf,    -inf,\n","            -inf,    -inf]], device='cuda:0')\n","log_transition_matrix tensor([[-inf, 0.],\n","        [0., -inf]], device='cuda:0')\n","tensor([[[-3.8771,    -inf],\n","         [   -inf, -5.8482],\n","         [-9.8778,    -inf]]], device='cuda:0')\n","log_sums tensor([[-3.8771, -5.8482, -9.8778]], device='cuda:0')\n","tensor([[-9.8778]], device='cuda:0')\n"]}]},{"cell_type":"code","metadata":{"id":"8rMAmf-UGhbw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6ca8b72e-9708-47fe-f7d8-136e23edbb31","executionInfo":{"status":"ok","timestamp":1672935109693,"user_tz":-540,"elapsed":282,"user":{"displayName":"김정인","userId":"08669711361714769540"}}},"source":["x = torch.stack( [torch.tensor(encode(\"aba\")), torch.tensor(encode(\"abb\"))] )\n","print(x)\n","T = torch.tensor([3,3])\n","print(model.forward(x, T))"],"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0, 1, 0],\n","        [0, 1, 1]])\n","tensor([-0.4741, -0.9741], device='cuda:0')\n","emission_model_forward tensor([0, 0], device='cuda:0')\n","tensor([[   -inf, -3.1207, -3.4031, -2.8951,    -inf, -3.4414, -2.5423, -3.7510,\n","            -inf, -2.1494, -4.1715, -4.7487, -3.4030, -4.1364,    -inf, -3.0860,\n","         -3.4701, -3.4584, -2.8435, -4.0296,    -inf, -2.0517, -3.8177, -2.2294,\n","         -3.7313, -2.5654],\n","        [-1.9711,    -inf,    -inf,    -inf, -1.8195,    -inf,    -inf,    -inf,\n","         -3.4084,    -inf,    -inf,    -inf,    -inf,    -inf, -1.0908,    -inf,\n","            -inf,    -inf,    -inf,    -inf, -1.1100,    -inf,    -inf,    -inf,\n","            -inf,    -inf]], device='cuda:0')\n","tensor([[[   -inf, -2.9452],\n","         [ 0.0000,  0.0000],\n","         [ 0.0000,  0.0000]],\n","\n","        [[   -inf, -2.9452],\n","         [ 0.0000,  0.0000],\n","         [ 0.0000,  0.0000]]], device='cuda:0')\n","emission_model_forward tensor([1, 1], device='cuda:0')\n","tensor([[   -inf, -3.1207, -3.4031, -2.8951,    -inf, -3.4414, -2.5423, -3.7510,\n","            -inf, -2.1494, -4.1715, -4.7487, -3.4030, -4.1364,    -inf, -3.0860,\n","         -3.4701, -3.4584, -2.8435, -4.0296,    -inf, -2.0517, -3.8177, -2.2294,\n","         -3.7313, -2.5654],\n","        [-1.9711,    -inf,    -inf,    -inf, -1.8195,    -inf,    -inf,    -inf,\n","         -3.4084,    -inf,    -inf,    -inf,    -inf,    -inf, -1.0908,    -inf,\n","            -inf,    -inf,    -inf,    -inf, -1.1100,    -inf,    -inf,    -inf,\n","            -inf,    -inf]], device='cuda:0')\n","log_transition_matrix tensor([[-inf, 0.],\n","        [0., -inf]], device='cuda:0')\n","tensor([[[   -inf, -2.9452],\n","         [-6.0659,    -inf],\n","         [ 0.0000,  0.0000]],\n","\n","        [[   -inf, -2.9452],\n","         [-6.0659,    -inf],\n","         [ 0.0000,  0.0000]]], device='cuda:0')\n","emission_model_forward tensor([0, 1], device='cuda:0')\n","tensor([[   -inf, -3.1207, -3.4031, -2.8951,    -inf, -3.4414, -2.5423, -3.7510,\n","            -inf, -2.1494, -4.1715, -4.7487, -3.4030, -4.1364,    -inf, -3.0860,\n","         -3.4701, -3.4584, -2.8435, -4.0296,    -inf, -2.0517, -3.8177, -2.2294,\n","         -3.7313, -2.5654],\n","        [-1.9711,    -inf,    -inf,    -inf, -1.8195,    -inf,    -inf,    -inf,\n","         -3.4084,    -inf,    -inf,    -inf,    -inf,    -inf, -1.0908,    -inf,\n","            -inf,    -inf,    -inf,    -inf, -1.1100,    -inf,    -inf,    -inf,\n","            -inf,    -inf]], device='cuda:0')\n","log_transition_matrix tensor([[-inf, 0.],\n","        [0., -inf]], device='cuda:0')\n","tensor([[[   -inf, -2.9452],\n","         [-6.0659,    -inf],\n","         [   -inf, -8.0370]],\n","\n","        [[   -inf, -2.9452],\n","         [-6.0659,    -inf],\n","         [   -inf,    -inf]]], device='cuda:0')\n","log_sums tensor([[-2.9452, -6.0659, -8.0370],\n","        [-2.9452, -6.0659,    -inf]], device='cuda:0')\n","tensor([[-8.0370],\n","        [   -inf]], device='cuda:0')\n"]}]},{"cell_type":"markdown","metadata":{"id":"95TB2gvNHuLn"},"source":["위에서 모음 <-> 자음 HMM을 사용할 때 정방향 알고리즘은 $\\mathbf{x} = \\text{\"abb\"}$에 대해 $-\\infty$를 반환합니다. 전이 행렬이 모음 -> 모음과 자음 -> 자음의 확률이 0이라고 말하므로 $\\text{\"abb\"}$가 발생할 확률은 0이므로 로그 확률은 $-\\infty$입니다."]},{"cell_type":"markdown","metadata":{"id":"qBCrFobsEM8X"},"source":["#### *참고: 정방향 알고리즘 도출*\n","\n","순방향 알고리즘이 실제로 $p(\\mathbf{x})$를 계산하는 방법을 이해하는 데 관심이 있다면 이 섹션을 읽으십시오. 그렇지 않은 경우 \"문제 2\"의 다음 부분(가장 가능성이 높은 상태 시퀀스 찾기)으로 건너뜁니다."]},{"cell_type":"markdown","metadata":{"id":"CpHWWKcxhjkx"},"source":["\n","\n","forward algorithm을 도출하려면 먼저 forward variable 를 도출합니다.\n","\n","$\n","\\begin{align} \n","    \\alpha_{s,t} &= p(x_1, x_2, \\dots, x_t, z_t=s) \\\\\n","     &= p(x_t | x_1, x_2, \\dots, x_{t-1}, z_t = s) \\cdot p(x_1, x_2, \\dots, x_{t-1}, z_t = s)  \\\\ \n","    &= p(x_t | z_t = s) \\cdot p(x_1, x_2, \\dots, x_{t-1}, z_t = s) \\\\\n","    &= p(x_t | z_t = s) \\cdot \\left( \\sum_{s'} p(x_1, x_2, \\dots, x_{t-1}, z_{t-1}=s', z_t = s) \\right)\\\\\n","    &= p(x_t | z_t = s) \\cdot \\left( \\sum_{s'} p(z_t = s | x_1, x_2, \\dots, x_{t-1}, z_{t-1}=s') \\cdot p(x_1, x_2, \\dots, x_{t-1}, z_{t-1}=s') \\right)\\\\\n","    &= \\underbrace{p(x_t | z_t = s)}_{\\text{emission model}} \\cdot \\left( \\sum_{s'} \\underbrace{p(z_t = s | z_{t-1}=s')}_{\\text{transition model}} \\cdot \\underbrace{p(x_1, x_2, \\dots, x_{t-1}, z_{t-1}=s')}_{\\text{forward variable for previous timestep}} \\right)\\\\\n","    &= b_s(x_t) \\cdot \\left( \\sum_{s'} A_{s, s'} \\cdot \\alpha_{s',t-1} \\right)\n","\\end{align}\n","$\n","\n","이전 줄에서 이 방정식의 각 줄로 이동하는 방법을 설명하겠습니다.\n","\n","라인 1은 정방향 변수 $\\alpha_{s,t}$의 정의입니다.\n","\n","2행은 체인 규칙($p(A,B) = p(A|B) \\cdot p(B)$, 여기서 $A$는 $x_t$이고 $B$는 다른 모든 변수임)입니다.\n","\n","3행에서는 가정 2를 적용합니다. 관측 확률 $x_t$는 현재 상태 $z_t$에만 의존합니다.\n","\n","4행에서는 이전 타임스텝 $t-1$에서 가능한 모든 상태를 주변화합니다.\n","\n","5행에서 체인 규칙을 다시 적용합니다.\n","\n","6행에서는 가정 1을 적용합니다. 현재 상태는 이전 상태에만 의존합니다.\n","\n","7행에서 방출 확률, 전이 확률 및 이전 시간 단계의 순방향 변수를 대체하여 완전한 재귀를 얻습니다."]},{"cell_type":"markdown","metadata":{"id":"kh1ovNjWDbIA"},"source":["위 공식은 $t = 2 \\rightarrow T$에 사용할 수 있습니다. $t=1$에서는 이전 상태가 없으므로 전이 행렬 $A$ 대신 각 상태에서 시작할 확률을 알려주는 상태 이전 $\\pi$를 사용합니다. 따라서 $t=1$의 경우 순방향 변수는 다음과 같이 계산됩니다.\n","\n","$$\\begin{align} \n","\\alpha_{s,1} &= p(x_1, z_1=s) \\\\\n","  &= p(x_1 | z_1 = s) \\cdot p(z_1 = s)  \\\\ \n","&= b_s(x_1) \\cdot \\pi_s\n","\\end{align}$$"]},{"cell_type":"markdown","metadata":{"id":"RRzSqkRkEWKX"},"source":["마지막으로 $p(\\mathbf{x}) = p(x_1, x_2, \\dots, x_T)$를 계산하기 위해 마지막 시간 단계에서 계산된 순방향 변수인 $\\alpha_{s,T}$를 주변화합니다.\n","\n","$$\\begin{align*} \n","p(\\mathbf{x}) &= \\sum_{s} p(x_1, x_2, \\dots, x_T, z_T = s) \\\\ \n","&= \\sum_{s} \\alpha_{s,T}\n","\\end{align*}$$"]},{"cell_type":"markdown","metadata":{"id":"qLBU8Iu7I5Tb"},"source":["정방향 변수의 로그를 취하고 다음 ID를 사용하여 이 공식에서 로그 도메인 공식으로 얻을 수 있습니다.\n","- $\\text{log }(a \\cdot b) = \\text{log }a + \\text{log }b$\n","- $\\text{log }(a + b) = \\text{log }(e^{\\text{log }a} + e^{\\text{log }b}) = \\text{logsumexp}(\\text{log }a, \\text{log }b)$"]},{"cell_type":"markdown","metadata":{"id":"bxivzF8hgpiW"},"source":["### 문제 2: $\\underset{\\mathbf{z}}{\\text{argmax }} p(\\mathbf{z}|\\mathbf{x})$를 어떻게 계산합니까?"]},{"cell_type":"markdown","metadata":{"id":"c1Kv2yyiN7SX"},"source":["관찰 시퀀스 $\\mathbf{x}$가 주어지면 $\\mathbf{x}$를 생성할 수 있는 가장 가능성 있는 상태 시퀀스를 찾고자 할 수 있습니다. (셀카 순서가 주어졌을 때 친구가 어떤 도시를 방문했는지 유추하고 싶습니다.) 즉, $\\underset{\\mathbf{z}}{\\text{argmax }} p(\\mathbf{z}|\\ mathbf{x})$.\n","\n","베이즈 규칙을 사용하여 이 식을 다시 작성할 수 있습니다.\n","$$\\begin{align*} \n","    \\underset{\\mathbf{z}}{\\text{argmax }} p(\\mathbf{z}|\\mathbf{x}) &= \\underset{\\mathbf{z}}{\\text{argmax }} \\frac{p(\\mathbf{x}|\\mathbf{z}) p(\\mathbf{z})}{p(\\mathbf{x})} \\\\ \n","    &= \\underset{\\mathbf{z}}{\\text{argmax }} p(\\mathbf{x}|\\mathbf{z}) p(\\mathbf{z})\n","\\end{align*}$$\n","\n","Hmm! 이 마지막 식은은, $\\underset{\\mathbf{z}}{\\text{argmax }} p(\\mathbf{x}|\\mathbf{z}) p(\\mathbf{z})$, forward algorithm을 도입 하기전에 접했던 다루기 힘든 표현과 의심스러울 정도로 유사해 보입니다. $\\underset{\\mathbf{z}}{\\sum} p(\\mathbf{x}|\\mathbf{z}) p(\\mathbf{z})$.\n","\n","그리고 실제로 모든 $\\mathbf{z}$에 대한 다루기 힘든 *sum*이 순방향 알고리즘을 사용하여 효율적으로 구현될 수 있는 것처럼 이 다루기 힘든 *argmax*도 유사한 분할 정복 알고리즘을 사용하여 효율적으로 구현될 수 있습니다. 전형적인 Viterbi 알고리즘!"]},{"cell_type":"markdown","metadata":{"id":"niKZEX5xWeWR"},"source":["________\n","\n","<u><b>The Viterbi Algorithm</b></u>\n","\n","> for $s=1 \\rightarrow N$:\\\n","> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\delta_{s,1} := b_s(x_1) \\cdot \\pi_s$\\\n","> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\psi_{s,1} := 0$\n",">\n","> for $t = 2 \\rightarrow T$:\\\n","> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for $s = 1 \\rightarrow N$:\\\n","> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\delta_{s,t} := b_s(x_t) \\cdot \\left( \\underset{s'}{\\text{max }} A_{s, s'} \\cdot \\delta_{s',t-1} \\right)$\\\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\psi_{s,t} := \\underset{s'}{\\text{argmax }} A_{s, s'} \\cdot \\delta_{s',t-1}$\n","> \n","> $z_T^* := \\underset{s}{\\text{argmax }} \\delta_{s,T}$\\\n","> for $t = T-1 \\rightarrow 1$:\\\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$z_{t}^* := \\psi_{z_{t+1}^*,t+1}$\n","> \n","> $\\mathbf{z}^* := \\{z_{1}^*, \\dots, z_{T}^* \\}$\\\n","return $\\mathbf{z}^*$\n","________"]},{"cell_type":"markdown","metadata":{"id":"UcHVTCucZV6K"},"source":["Viterbi 알고리즘은 순방향 알고리즘보다 다소 형편없어 보이지만 본질적으로 동일한 알고리즘이며 두 가지 조정이 있습니다. 1) 이전 상태에 대한 합계를 취하는 대신 최대값을 취합니다. 2) 이전 상태의 argmax를 테이블에 기록하고 마지막에 이 테이블을 반복하여 가장 가능성이 높은 상태 시퀀스인 $\\mathbf{z}^*$를 얻습니다. (그리고 순방향 알고리즘과 마찬가지로 더 나은 수치적 안정성을 위해 로그 도메인에서 Viterbi 알고리즘을 실행해야 합니다.)"]},{"cell_type":"markdown","metadata":{"id":"NlN7IY_JZ5A-"},"source":["Viterbi 알고리즘을 PyTorch 모델에 추가해 보겠습니다."]},{"cell_type":"code","source":["a = torch.tensor([0.1, 0.9])\n","out1,out2 = torch.max(a, dim=0)\n","print(out1,out2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N2YMe-7v_QK6","executionInfo":{"status":"ok","timestamp":1672939968131,"user_tz":-540,"elapsed":280,"user":{"displayName":"김정인","userId":"08669711361714769540"}},"outputId":"9d6aa345-a63e-4540-8b29-6ce92837644d"},"execution_count":88,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.9000) tensor(1)\n"]}]},{"cell_type":"code","source":["a = torch.tensor([[0.1, 0.9],\n","                  [0.8, 0.2]])\n","out1,out2 = torch.max(a, dim=1)\n","print(out1,out2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ROy3mY9W_jHi","executionInfo":{"status":"ok","timestamp":1672940005838,"user_tz":-540,"elapsed":290,"user":{"displayName":"김정인","userId":"08669711361714769540"}},"outputId":"960022e9-5c89-4226-b9ee-44f385ab30c6"},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.9000, 0.8000]) tensor([1, 0])\n"]}]},{"cell_type":"code","source":["a = torch.tensor([[0.5, 0.5],\n","                  [0.8, 0.2]])\n","out1,out2 = torch.max(a, dim=1)\n","print(out1,out2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7WoBmoeB_wiL","executionInfo":{"status":"ok","timestamp":1672940039332,"user_tz":-540,"elapsed":1,"user":{"displayName":"김정인","userId":"08669711361714769540"}},"outputId":"72a5a1ab-ab63-4604-b946-e21d1573c365"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.5000, 0.8000]) tensor([0, 0])\n"]}]},{"cell_type":"code","source":["a = [1,2,3]\n","a.insert(0,4)\n","print(a)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E1Nzi_lKDNTt","executionInfo":{"status":"ok","timestamp":1672941006694,"user_tz":-540,"elapsed":2,"user":{"displayName":"김정인","userId":"08669711361714769540"}},"outputId":"9e93e0bc-69e0-44d8-ff6a-86149fbce750"},"execution_count":96,"outputs":[{"output_type":"stream","name":"stdout","text":["[4, 1, 2, 3]\n"]}]},{"cell_type":"code","metadata":{"id":"qeDG8DVmZ-P0","executionInfo":{"status":"ok","timestamp":1672941533200,"user_tz":-540,"elapsed":1,"user":{"displayName":"김정인","userId":"08669711361714769540"}}},"source":["def viterbi(self, x, T):\n","  \"\"\"\n","  x : IntTensor of shape (batch size, T_max)\n","  T : IntTensor of shape (batch size)\n","  Find argmax_z log p(x|z) for each (x) in the batch.\n","  \"\"\"\n","  if self.is_cuda:\n","    x = x.cuda()\n","    T = T.cuda()\n","\n","  batch_size = x.shape[0]; T_max = x.shape[1]\n","  log_state_priors = torch.nn.functional.log_softmax(self.unnormalized_state_priors, dim=0)\n","  log_delta = torch.zeros(batch_size, T_max, self.N).float()\n","  psi = torch.zeros(batch_size, T_max, self.N).long()\n","  if self.is_cuda:\n","    log_delta = log_delta.cuda()\n","    psi = psi.cuda()\n","\n","  log_delta[:, 0, :] = self.emission_model(x[:,0]) + log_state_priors\n","  for t in range(1, T_max):\n","    max_val, argmax_val = self.transition_model.maxmul(log_delta[:, t-1, :])\n","    log_delta[:, t, :] = self.emission_model(x[:,t]) + max_val\n","    psi[:, t, :] = argmax_val\n","\n","#   print(\"log_delt\", log_delta)\n","#   print(\"psi\", psi)\n","\n","  # Get the log probability of the best path\n","  log_max = log_delta.max(dim=2)[0]\n","  best_path_scores = torch.gather(log_max, 1, T.view(-1,1) - 1)\n","\n","  # This next part is a bit tricky to parallelize across the batch,\n","  # so we will do it separately for each example.\n","  z_star = []\n","  for i in range(0, batch_size):\n","    z_star_i = [ log_delta[i, T[i] - 1, :].max(dim=0)[1].item() ]\n","    for t in range(T[i] - 1, 0, -1):\n","      z_t = psi[i, t, z_star_i[0]].item()\n","      z_star_i.insert(0, z_t)\n","\n","    z_star.append(z_star_i)\n","\n","  return z_star, best_path_scores # return both the best path and its log probability\n","\n","def transition_model_maxmul(self, log_alpha):\n","  log_transition_matrix = torch.nn.functional.log_softmax(self.unnormalized_transition_matrix, dim=0)\n","\n","  out1, out2 = maxmul(log_transition_matrix, log_alpha.transpose(0,1))\n","  return out1.transpose(0,1), out2.transpose(0,1)\n","\n","def maxmul(log_A, log_B):\n","\t\"\"\"\n","\tlog_A : m x n\n","\tlog_B : n x p\n","\toutput : m x p matrix\n","\n","\tSimilar to the log domain matrix multiplication,\n","\tthis computes out_{i,j} = max_k log_A_{i,k} + log_B_{k,j}\n","\t\"\"\"\n","\tm = log_A.shape[0]\n","\tn = log_A.shape[1]\n","\tp = log_B.shape[1]\n","\n","\tlog_A_expanded = torch.stack([log_A] * p, dim=2)\n","\tlog_B_expanded = torch.stack([log_B] * m, dim=0)\n","\n","\telementwise_sum = log_A_expanded + log_B_expanded\n","\tout1,out2 = torch.max(elementwise_sum, dim=1)\n","\n","\treturn out1,out2\n","\n","TransitionModel.maxmul = transition_model_maxmul\n","HMM.viterbi = viterbi"],"execution_count":103,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uTGOaeXbaWie"},"source":["모음/자음 HMM이 주어지면 입력 시퀀스에서 Viterbi를 실행해 보십시오."]},{"cell_type":"code","source":["x = torch.stack( [torch.tensor(encode(\"cat\"))] )\n","T = torch.tensor([3])\n","print(model.viterbi(x, T))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UpwMTfwqxWyD","executionInfo":{"status":"ok","timestamp":1672941539688,"user_tz":-540,"elapsed":267,"user":{"displayName":"김정인","userId":"08669711361714769540"}},"outputId":"d42b397a-10b1-4dfe-fd84-d02b1f4dbe99"},"execution_count":104,"outputs":[{"output_type":"stream","name":"stdout","text":["([[0, 1, 0]], tensor([[-9.8778]], device='cuda:0'))\n"]}]},{"cell_type":"code","metadata":{"id":"zeOTbaIMc23d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672941544379,"user_tz":-540,"elapsed":333,"user":{"displayName":"김정인","userId":"08669711361714769540"}},"outputId":"1a01d87e-40c0-48ea-a7a0-6618cbf0cd1d"},"source":["x = torch.stack( [torch.tensor(encode(\"aba\")), torch.tensor(encode(\"abb\"))] )\n","T = torch.tensor([3,3])\n","print(model.viterbi(x, T))"],"execution_count":105,"outputs":[{"output_type":"stream","name":"stdout","text":["([[1, 0, 1], [1, 0, 0]], tensor([[-8.0370],\n","        [   -inf]], device='cuda:0'))\n"]}]},{"cell_type":"markdown","metadata":{"id":"fKr8YlafdzBx"},"source":["$\\mathbf{x} = \\text{\"aba\"}$의 경우 Viterbi 알고리즘은 $\\mathbf{z}^* = \\{1,0,1\\}$를 반환합니다. 이것은 위의 상태를 정의한 방식에 따라 \"모음, 자음, 모음\"에 해당하며, 이 입력 시퀀스에 맞습니다.\n","\n","$\\mathbf{x} = \\text{\"abb\"}$의 경우 Viterbi 알고리즘은 여전히 $\\mathbf{z}^*$를 반환하지만 \"모음, 자음, 자음\"은 이 HMM이고 실제로 이 경로의 로그 확률은 $-\\infty$입니다."]},{"cell_type":"markdown","metadata":{"id":"nCWw0_WienO_"},"source":["\"순방향 점수\"(순방향 알고리즘에 의해 반환된 모든 가능한 경로의 로그 확률)와 \"Viterbi 점수\"(Viterbi 알고리즘에 의해 반환된 최대 우도 경로의 로그 확률)를 비교해 보겠습니다."]},{"cell_type":"code","metadata":{"id":"L9fBOHvdeqWC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"40d7bb4d-dd21-4792-cfa7-56570ed72fb4","executionInfo":{"status":"ok","timestamp":1672941551487,"user_tz":-540,"elapsed":290,"user":{"displayName":"김정인","userId":"08669711361714769540"}}},"source":["x = torch.stack( [torch.tensor(encode(\"cat\"))] )\n","T = torch.tensor([3])\n","print(model.forward(x, T))\n","print(model.viterbi(x, T)[1])"],"execution_count":106,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-9.8778]], device='cuda:0')\n","tensor([[-9.8778]], device='cuda:0')\n"]}]},{"cell_type":"markdown","metadata":{"id":"InF6PJVOfHwH"},"source":["두 점수는 동일합니다! 이 경우 HMM을 통과하는 가능한 경로는 하나뿐이므로 가장 가능성이 높은 경로의 확률은 가능한 모든 경로의 확률의 합과 동일하기 때문입니다.\n","\n","그러나 일반적으로 포워드 스코어와 Viterbi 스코어는 항상 다소 비슷합니다. 이는 $\\text{logsumexp}$ 함수의 속성인 $\\text{logsumexp}(\\mathbf{x}) \\approx \\max (\\mathbf{x})$ 때문입니다. ($\\text{logsumexp}$는 \"smooth maximum\" 함수라고도 합니다.)"]},{"cell_type":"code","metadata":{"id":"x__70tB6gnkF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cb2ed351-a98f-427a-a196-69804e8d3800","executionInfo":{"status":"ok","timestamp":1672941404463,"user_tz":-540,"elapsed":268,"user":{"displayName":"김정인","userId":"08669711361714769540"}}},"source":["x = torch.tensor([1., 2., 3.])\n","print(x.max(dim=0)[0])\n","print(x.logsumexp(dim=0))"],"execution_count":101,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(3.)\n","tensor(3.4076)\n"]}]},{"cell_type":"markdown","metadata":{"id":"SvFtiWhzgy0V"},"source":["### 문제 3: 모델을 어떻게 학습시키나요?\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"r3JaykRalSBZ"},"source":["이전에는 특정 동작을 갖도록 HMM을 하드 코딩했습니다. 대신 우리가 하고 싶은 것은 HMM이 자체적으로 데이터를 모델링하는 방법을 배우게 하는 것입니다. 상태가 특정 해석을 갖도록 HMM과 함께 지도 학습을 사용할 수 있지만(방출 모델 또는 전환 모델을 하드 코딩하여) HMM의 정말 멋진 점은 자연스럽게 비지도 학습자라는 점입니다. 프로그래머가 각 상태의 의미를 표시할 필요 없이 서로 다른 상태를 사용하여 데이터의 서로 다른 패턴을 나타내는 방법을 배울 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"8K471fT4N-PR"},"source":["많은 기계 학습 모델과 마찬가지로 HMM은 다음과 같이 최대 우도 추정을 사용하여 훈련할 수 있습니다.\n","\n","$$\\theta^* = \\underset{\\theta}{\\text{argmin }} -\\sum_{\\mathbf{x}^i}\\text{log }p_{\\theta}(\\mathbf{x}^i)$$\n","\n","여기서 $\\mathbf{x}^1, \\mathbf{x}^2, \\dots$는 훈련 예시입니다.\n","\n","이를 위한 표준 방법은 EM(Expectation-Maximization) 알고리즘이며 HMM의 경우 \"Baum-Welch\" 알고리즘이라고도 합니다. EM 교육에서는 잠재 변수의 값을 추정하는 \"E-단계\"와 추정된 잠재 변수에 따라 모델 매개변수가 업데이트되는 \"M-단계\"를 번갈아 사용합니다. ($k$-각 데이터 포인트가 속한 클러스터를 추측한 다음 클러스터가 있는 위치를 다시 추정하고 반복합니다.) EM 알고리즘에는 몇 가지 좋은 속성이 있습니다. 각 단계에서 손실 함수를 줄이기 위해 보장됩니다. E-step 및 M-step은 정확한 폐쇄형 솔루션을 가질 수 있으며, 이 경우 성가신 학습 속도가 필요하지 않습니다.\n","\n","그러나 HMM 순방향 알고리즘은 모든 모델 매개변수와 관련하여 미분 가능하기 때문에 PyTorch와 같은 라이브러리에서 자동 미분 방법을 활용하고 $-\\text{log }p_{\\theta}(\\mathbf{ x})$ 직접, 정방향 알고리즘을 통해 역전파하고 확률적 경사 하강법을 실행합니다. 즉, 훈련을 구현하기 위해 추가 HMM 코드를 작성할 필요가 없습니다. `loss.backward()`만 있으면 됩니다."]},{"cell_type":"markdown","metadata":{"id":"aVh0-369qZDC"},"source":["여기서는 PyTorch에서 HMM에 대한 SGD 교육을 구현합니다. 먼저 일부 도우미 클래스:"]},{"cell_type":"code","metadata":{"id":"KqiFobGHwdzc","executionInfo":{"status":"ok","timestamp":1672942099093,"user_tz":-540,"elapsed":1044,"user":{"displayName":"김정인","userId":"08669711361714769540"}}},"source":["import torch.utils.data\n","from collections import Counter\n","from sklearn.model_selection import train_test_split\n","\n","class TextDataset(torch.utils.data.Dataset):\n","  def __init__(self, lines):\n","    self.lines = lines # list of strings\n","    collate = Collate() # function for generating a minibatch from strings\n","    self.loader = torch.utils.data.DataLoader(self, batch_size=1024, num_workers=1, shuffle=True, collate_fn=collate)\n","\n","  def __len__(self):\n","    return len(self.lines)\n","\n","  def __getitem__(self, idx):\n","    line = self.lines[idx].lstrip(\" \").rstrip(\"\\n\").rstrip(\" \").rstrip(\"\\n\")\n","    return line\n","\n","class Collate:\n","  def __init__(self):\n","    pass\n","\n","  def __call__(self, batch):\n","    \"\"\"\n","    Returns a minibatch of strings, padded to have the same length.\n","    \"\"\"\n","    x = []\n","    batch_size = len(batch)\n","    for index in range(batch_size):\n","      x_ = batch[index]\n","\n","      # convert letters to integers\n","      x.append(encode(x_))\n","\n","    # pad all sequences with 0 to have same length\n","    x_lengths = [len(x_) for x_ in x]\n","    T = max(x_lengths)\n","    for index in range(batch_size):\n","      x[index] += [0] * (T - len(x[index]))\n","      x[index] = torch.tensor(x[index])\n","\n","    # stack into single tensor\n","    x = torch.stack(x)\n","    x_lengths = torch.tensor(x_lengths)\n","    return (x,x_lengths)"],"execution_count":107,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YpDpwnPnAEA9"},"source":["학습/테스트 데이터를 로드해 보겠습니다. 기본적으로 이것은 유닉스 \"단어\" 파일을 사용하지만 자신의 텍스트 파일을 사용할 수도 있습니다."]},{"cell_type":"code","metadata":{"id":"52NqFHg8ANsB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"55338581-6a40-4ff3-e9c5-26bd7264798a","executionInfo":{"status":"ok","timestamp":1672942246259,"user_tz":-540,"elapsed":1288,"user":{"displayName":"김정인","userId":"08669711361714769540"}}},"source":["!wget https://raw.githubusercontent.com/lorenlugosch/pytorch_HMM/master/data/train/training.txt\n","\n","filename = \"training.txt\"\n","\n","with open(filename, \"r\") as f:\n","  lines = f.readlines() # each line of lines will have one word\n","\n","alphabet = list(Counter((\"\".join(lines))).keys())\n","train_lines, valid_lines = train_test_split(lines, test_size=0.1, random_state=42)\n","train_dataset = TextDataset(train_lines)\n","valid_dataset = TextDataset(valid_lines)\n","\n","M = len(alphabet)"],"execution_count":108,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-01-05 18:10:46--  https://raw.githubusercontent.com/lorenlugosch/pytorch_HMM/master/data/train/training.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2493109 (2.4M) [text/plain]\n","Saving to: ‘training.txt’\n","\n","training.txt        100%[===================>]   2.38M  --.-KB/s    in 0.05s   \n","\n","2023-01-05 18:10:47 (47.6 MB/s) - ‘training.txt’ saved [2493109/2493109]\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"H0AqmyrK7IUn"},"source":["모델을 훈련하고 테스트하기 위해 Trainer 클래스를 사용합니다.\n","\n"]},{"cell_type":"code","metadata":{"id":"iypy_neX9cpq","executionInfo":{"status":"ok","timestamp":1672942356981,"user_tz":-540,"elapsed":321,"user":{"displayName":"김정인","userId":"08669711361714769540"}}},"source":["from tqdm import tqdm # for displaying progress bar\n","\n","class Trainer:\n","  def __init__(self, model, lr):\n","    self.model = model\n","    self.lr = lr\n","    self.optimizer = torch.optim.Adam(model.parameters(), lr=self.lr, weight_decay=0.00001)\n","  \n","  def train(self, dataset):\n","    train_loss = 0\n","    num_samples = 0\n","    self.model.train()\n","    print_interval = 50\n","    for idx, batch in enumerate(tqdm(dataset.loader)):\n","      x,T = batch\n","      batch_size = len(x)\n","      num_samples += batch_size\n","      log_probs = self.model(x,T)\n","      loss = -log_probs.mean()\n","      self.optimizer.zero_grad()\n","      loss.backward()\n","      self.optimizer.step()\n","      train_loss += loss.cpu().data.numpy().item() * batch_size\n","      if idx % print_interval == 0:\n","        print(\"loss:\", loss.item())\n","        for _ in range(5):\n","          sampled_x, sampled_z = self.model.sample()\n","          print(decode(sampled_x))\n","          print(sampled_z)\n","    train_loss /= num_samples\n","    return train_loss\n","\n","  def test(self, dataset):\n","    test_loss = 0\n","    num_samples = 0\n","    self.model.eval()\n","    print_interval = 50\n","    for idx, batch in enumerate(dataset.loader):\n","      x,T = batch\n","      batch_size = len(x)\n","      num_samples += batch_size\n","      log_probs = self.model(x,T)\n","      loss = -log_probs.mean()\n","      test_loss += loss.cpu().data.numpy().item() * batch_size\n","      if idx % print_interval == 0:\n","        print(\"loss:\", loss.item())\n","        sampled_x, sampled_z = self.model.sample()\n","        print(decode(sampled_x))\n","        print(sampled_z)\n","    test_loss /= num_samples\n","    return test_loss"],"execution_count":109,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mUR8qbHm9dMg"},"source":["마지막으로 모델을 초기화하고 기본 교육 루프를 실행합니다. 코드는 배치 50개마다 모델에서 몇 개의 샘플을 생성합니다. 시간이 지남에 따라 이러한 샘플은 점점 더 사실적으로 보일 것입니다."]},{"cell_type":"code","metadata":{"id":"1-NGIK1Q9g2C","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3b7abe27-a146-4c17-b744-22e06d5f7c9e","executionInfo":{"status":"ok","timestamp":1672942441150,"user_tz":-540,"elapsed":55630,"user":{"displayName":"김정인","userId":"08669711361714769540"}}},"source":["# Initialize model\n","model = HMM(N=64, M=M)\n","\n","# Train the model\n","num_epochs = 10\n","trainer = Trainer(model, lr=0.01)\n","\n","for epoch in range(num_epochs):\n","        print(\"========= Epoch %d of %d =========\" % (epoch+1, num_epochs))\n","        train_loss = trainer.train(train_dataset)\n","        valid_loss = trainer.test(valid_dataset)\n","\n","        print(\"========= Results: epoch %d of %d =========\" % (epoch+1, num_epochs))\n","        print(\"train loss: %.2f| valid loss: %.2f\\n\" % (train_loss, valid_loss) )"],"execution_count":110,"outputs":[{"output_type":"stream","name":"stdout","text":["========= Epoch 1 of 10 =========\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 1/208 [00:00<00:40,  5.17it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 38.98460388183594\n","KSHnmdKPMg\n","[57, 50, 20, 62, 7, 59, 17, 51, 3, 27]\n","oEbdcE\n","hFN\n","[28, 40, 25, 47, 56, 2, 35, 4, 3, 28]\n","gOTeIVDTyN\n","[48, 13, 54, 54, 0, 13, 26, 27, 25, 44]\n","f-OdHrIZ\n","t\n","[23, 38, 35, 19, 52, 17, 37, 26, 11, 41]\n","NThgLCYcwS\n","[13, 54, 35, 48, 44, 38, 54, 34, 58, 17]\n"]},{"output_type":"stream","name":"stderr","text":[" 26%|██▋       | 55/208 [00:01<00:03, 41.08it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 33.52580261230469\n","tTcaQRJIOV\n","[6, 63, 19, 3, 10, 0, 56, 43, 35, 62]\n","vatstCARah\n","[41, 24, 29, 39, 62, 17, 32, 45, 13, 0]\n","SDWynShPBi\n","[60, 63, 42, 46, 33, 24, 48, 38, 21, 42]\n","kfYDTr-MHm\n","[27, 53, 20, 24, 55, 20, 38, 60, 33, 8]\n","kRoSsUnul-\n","[29, 49, 16, 24, 11, 10, 0, 56, 24, 27]\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|█████     | 105/208 [00:02<00:02, 41.38it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 30.354246139526367\n","OnJSejiosn\n","[25, 45, 22, 61, 37, 21, 33, 37, 23, 63]\n","aaynlMntpa\n","[29, 61, 54, 63, 33, 19, 48, 62, 13, 32]\n","rLrtlmInsr\n","[60, 4, 63, 51, 39, 56, 59, 37, 0, 0]\n","pxyuqmtetu\n","[60, 27, 10, 18, 53, 37, 57, 37, 0, 12]\n","aJIOaLgCun\n","[13, 32, 16, 45, 46, 46, 48, 30, 56, 55]\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▍  | 155/208 [00:03<00:01, 41.15it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 28.13050079345703\n","cesEurliej\n","[43, 37, 24, 18, 62, 25, 24, 62, 24, 37]\n","Ynaopnnntr\n","[8, 63, 6, 16, 46, 48, 55, 16, 24, 55]\n","pcBfoKn\n","kr\n","[60, 37, 51, 9, 37, 43, 61, 10, 46, 51]\n","rlabcBiTer\n","[6, 39, 16, 54, 37, 21, 10, 6, 37, 23]\n","Optehgiial\n","[59, 37, 18, 62, 63, 53, 33, 46, 34, 18]\n"]},{"output_type":"stream","name":"stderr","text":[" 99%|█████████▊| 205/208 [00:04<00:00, 39.15it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 26.4641170501709\n","fvlLpsiewy\n","[60, 45, 39, 46, 36, 48, 62, 25, 18, 3]\n","oRuragesal\n","[13, 0, 56, 48, 46, 43, 37, 24, 37, 42]\n","noDlVetiNi\n","[21, 56, 37, 24, 19, 37, 43, 61, 42, 62]\n","chrnv-tueo\n","[25, 32, 23, 17, 9, 62, 57, 42, 62, 0]\n","evurnpujme\n","[37, 43, 61, 42, 62, 25, 46, 57, 4, 8]\n"]},{"output_type":"stream","name":"stderr","text":["\r100%|██████████| 208/208 [00:05<00:00, 41.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss: 26.14570426940918\n","ungtaNgerc\n","[29, 16, 1, 18, 8, 63, 19, 37, 23, 53]\n","========= Results: epoch 1 of 10 =========\n","train loss: 30.95| valid loss: 26.37\n","\n","========= Epoch 2 of 10 =========\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 1/208 [00:00<00:30,  6.74it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 26.653369903564453\n","bsiusichen\n","[30, 20, 62, 16, 24, 33, 51, 32, 37, 63]\n","unaaiIaila\n","[29, 63, 8, 42, 62, 41, 39, 33, 43, 37]\n","celaclBrit\n","[29, 63, 43, 8, 22, 42, 62, 19, 33, 19]\n","puxenmDroD\n","[60, 62, 59, 37, 63, 43, 37, 36, 16, 63]\n","VoGo-Wigat\n","[30, 46, 30, 46, 37, 24, 37, 43, 8, 19]\n"]},{"output_type":"stream","name":"stderr","text":[" 26%|██▋       | 55/208 [00:01<00:03, 42.12it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 25.33864402770996\n","beuorymeda\n","[59, 37, 45, 46, 63, 62, 43, 37, 43, 37]\n","drrRpHrens\n","[23, 27, 10, 46, 48, 46, 48, 6, 63, 51]\n","mytichazul\n","[48, 62, 19, 33, 51, 32, 37, 23, 62, 42]\n","bevesensty\n","[30, 8, 19, 37, 24, 37, 63, 33, 18, 62]\n","Ceteuterry\n","[30, 8, 19, 33, 46, 19, 37, 63, 19, 62]\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|█████     | 105/208 [00:02<00:02, 39.23it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 25.06123161315918\n","tnansondel\n","[6, 63, 8, 63, 25, 46, 63, 43, 10, 0]\n","menledinal\n","[48, 62, 43, 42, 37, 23, 62, 63, 8, 22]\n","thonateJli\n","[18, 32, 46, 63, 8, 19, 37, 24, 0, 56]\n","fastiterin\n","[30, 8, 24, 19, 33, 19, 37, 23, 62, 63]\n","unlhsenlio\n","[29, 63, 18, 32, 55, 37, 63, 43, 33, 46]\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▍  | 155/208 [00:03<00:01, 40.26it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 24.35223388671875\n","bommcychap\n","[30, 46, 48, 55, 43, 62, 51, 32, 46, 57]\n","Malulycrii\n","[30, 8, 22, 61, 42, 62, 18, 4, 33, 51]\n","plebloplit\n","[57, 42, 62, 22, 42, 62, 57, 42, 62, 18]\n","Cyoamabata\n","[60, 62, 48, 8, 19, 6, 59, 37, 18, 46]\n","Hatinammet\n","[30, 8, 19, 37, 63, 8, 48, 55, 37, 18]\n"]},{"output_type":"stream","name":"stderr","text":[" 99%|█████████▊| 205/208 [00:04<00:00, 40.02it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 24.586641311645508\n","dnnniHustu\n","[43, 8, 63, 43, 33, 15, 56, 24, 19, 37]\n","phidarabey\n","[57, 32, 62, 43, 8, 48, 8, 22, 42, 62]\n","rencaasyoy\n","[30, 37, 63, 18, 8, 22, 42, 62, 46, 63]\n","pephysench\n","[30, 62, 57, 4, 62, 19, 37, 63, 18, 32]\n","fanthimant\n","[30, 8, 63, 18, 32, 33, 43, 8, 63, 19]\n"]},{"output_type":"stream","name":"stderr","text":["\r100%|██████████| 208/208 [00:05<00:00, 40.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss: 24.166675567626953\n","diTterifis\n","[43, 33, 51, 32, 37, 23, 33, 43, 37, 24]\n","========= Results: epoch 2 of 10 =========\n","train loss: 25.02| valid loss: 24.37\n","\n","========= Epoch 3 of 10 =========\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 1/208 [00:00<00:30,  6.90it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 24.335113525390625\n","burienetsi\n","[30, 37, 23, 55, 37, 63, 37, 24, 19, 37]\n","imurercQro\n","[29, 48, 37, 42, 37, 23, 43, 37, 48, 6]\n","Cappiansen\n","[30, 8, 48, 57, 32, 37, 63, 25, 61, 63]\n","aoBpragero\n","[6, 48, 6, 57, 4, 8, 19, 37, 23, 46]\n","hycutoniEe\n","[60, 62, 51, 56, 18, 46, 63, 33, 18, 62]\n"]},{"output_type":"stream","name":"stderr","text":[" 27%|██▋       | 56/208 [00:01<00:03, 41.76it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 24.103038787841797\n","siticsicse\n","[25, 61, 19, 33, 24, 19, 33, 24, 19, 37]\n","vitatelgeg\n","[43, 33, 51, 8, 19, 37, 23, 60, 62, 41]\n","morthnoNsy\n","[48, 46, 63, 18, 32, 10, 46, 63, 25, 62]\n","bosolelbed\n","[30, 8, 48, 33, 22, 61, 22, 43, 37, 23]\n","Civexichoe\n","[30, 61, 59, 37, 48, 33, 51, 32, 46, 37]\n"]},{"output_type":"stream","name":"stderr","text":[" 51%|█████     | 106/208 [00:02<00:02, 42.70it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.972915649414062\n","tatintescu\n","[18, 8, 19, 33, 63, 18, 62, 24, 18, 56]\n","dofoestres\n","[43, 46, 9, 42, 37, 24, 19, 4, 62, 19]\n","cedmecista\n","[18, 37, 23, 48, 62, 43, 33, 24, 19, 8]\n","larriniabb\n","[39, 8, 23, 23, 33, 63, 33, 8, 22, 21]\n","minichospo\n","[30, 62, 63, 33, 51, 32, 46, 48, 57, 46]\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▌  | 156/208 [00:03<00:01, 39.73it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.99238395690918\n","peleolompe\n","[57, 37, 42, 33, 46, 48, 46, 48, 57, 37]\n","incaorinal\n","[29, 63, 51, 32, 46, 48, 33, 63, 8, 22]\n","risthizong\n","[43, 33, 24, 18, 32, 33, 59, 37, 63, 53]\n","myrypateli\n","[30, 62, 48, 62, 57, 8, 19, 37, 22, 33]\n","tryphlorec\n","[18, 4, 62, 24, 32, 10, 46, 48, 33, 51]\n"]},{"output_type":"stream","name":"stderr","text":[" 98%|█████████▊| 204/208 [00:05<00:00, 35.34it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.521535873413086\n","prartidert\n","[60, 4, 8, 23, 19, 33, 43, 37, 23, 58]\n","daridizedh\n","[43, 8, 23, 33, 43, 33, 59, 37, 23, 4]\n","ghobuathou\n","[60, 4, 6, 34, 56, 8, 18, 4, 46, 56]\n","euorgincer\n","[25, 56, 61, 63, 53, 61, 63, 43, 37, 23]\n","erglenceon\n","[37, 23, 51, 42, 37, 63, 18, 10, 46, 63]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 208/208 [00:05<00:00, 40.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss: 24.028894424438477\n","eriauqulon\n","[37, 23, 33, 8, 37, 0, 56, 48, 46, 63]\n","========= Results: epoch 3 of 10 =========\n","train loss: 24.05| valid loss: 23.89\n","\n","========= Epoch 4 of 10 =========\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 1/208 [00:00<00:32,  6.42it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.547264099121094\n","abronrWene\n","[6, 34, 4, 46, 63, 6, 59, 37, 23, 37]\n","unwancelgl\n","[29, 63, 53, 8, 63, 18, 8, 63, 53, 42]\n","subilinnis\n","[25, 56, 5, 6, 54, 61, 63, 43, 33, 43]\n","elydoRanor\n","[37, 42, 62, 43, 37, 23, 8, 63, 37, 23]\n","nithyemopl\n","[30, 62, 18, 32, 62, 8, 48, 62, 57, 42]\n"]},{"output_type":"stream","name":"stderr","text":[" 27%|██▋       | 56/208 [00:01<00:03, 40.28it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 24.07798957824707\n","tngliarsor\n","[29, 63, 53, 42, 33, 8, 23, 19, 37, 23]\n","obrematent\n","[6, 34, 4, 62, 48, 8, 19, 37, 63, 18]\n","tessagkenh\n","[18, 37, 24, 25, 8, 53, 27, 37, 43, 32]\n","honacenali\n","[30, 46, 63, 8, 18, 8, 63, 8, 22, 61]\n","pmexecamis\n","[57, 19, 37, 23, 62, 51, 8, 48, 33, 24]\n"]},{"output_type":"stream","name":"stderr","text":[" 51%|█████     | 106/208 [00:02<00:02, 41.87it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.889753341674805\n","toxphburme\n","[18, 46, 48, 57, 32, 31, 56, 48, 55, 37]\n","untritiaro\n","[29, 63, 18, 4, 33, 19, 33, 8, 22, 8]\n","besemydist\n","[30, 62, 48, 62, 48, 62, 43, 33, 24, 18]\n","aphyosoori\n","[6, 57, 32, 10, 46, 48, 62, 46, 48, 33]\n","Aitissussp\n","[30, 61, 19, 33, 24, 25, 56, 24, 25, 57]\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▌  | 156/208 [00:03<00:01, 43.12it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.681068420410156\n","sencolondl\n","[25, 37, 63, 43, 62, 22, 46, 63, 53, 42]\n","menanatJpa\n","[30, 62, 48, 8, 63, 8, 19, 33, 60, 8]\n","cinoniibli\n","[51, 61, 63, 46, 63, 33, 8, 22, 42, 33]\n","ipastorabo\n","[6, 18, 8, 24, 19, 37, 23, 8, 22, 46]\n","veliteVmel\n","[59, 37, 42, 62, 19, 37, 23, 55, 37, 22]\n"]},{"output_type":"stream","name":"stderr","text":[" 99%|█████████▉| 206/208 [00:05<00:00, 38.22it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 24.0616397857666\n","noDojtothe\n","[30, 46, 30, 46, 57, 19, 46, 18, 32, 62]\n","lummismont\n","[30, 56, 20, 55, 33, 24, 55, 37, 63, 19]\n","uromamytri\n","[29, 63, 46, 48, 8, 48, 62, 18, 4, 33]\n","adytonding\n","[8, 43, 62, 18, 46, 63, 43, 61, 63, 53]\n","terausouti\n","[18, 37, 4, 6, 56, 25, 0, 56, 19, 33]\n"]},{"output_type":"stream","name":"stderr","text":["\r100%|██████████| 208/208 [00:05<00:00, 41.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss: 23.54093360900879\n","ayerebtern\n","[8, 62, 8, 48, 37, 22, 18, 37, 23, 55]\n","========= Results: epoch 4 of 10 =========\n","train loss: 23.74| valid loss: 23.69\n","\n","========= Epoch 5 of 10 =========\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 1/208 [00:00<00:31,  6.61it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.83440399169922\n","ocestrocsi\n","[16, 43, 62, 24, 18, 4, 6, 24, 19, 33]\n","hanyleliog\n","[4, 8, 43, 62, 42, 62, 48, 33, 46, 48]\n","hockwigliv\n","[30, 46, 51, 58, 12, 61, 1, 42, 33, 59]\n","insschambr\n","[29, 63, 24, 25, 18, 32, 8, 20, 34, 4]\n","neizerchep\n","[30, 62, 61, 59, 37, 23, 51, 32, 62, 24]\n"]},{"output_type":"stream","name":"stderr","text":[" 27%|██▋       | 56/208 [00:01<00:03, 41.66it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.47636604309082\n","slyssionog\n","[25, 42, 62, 24, 19, 33, 46, 48, 46, 1]\n","prtsstussa\n","[60, 4, 6, 24, 25, 18, 56, 25, 10, 46]\n","slecerlest\n","[25, 42, 62, 43, 37, 23, 42, 62, 24, 19]\n","fuletautre\n","[40, 56, 39, 8, 18, 8, 45, 18, 4, 6]\n","cytistatri\n","[60, 62, 19, 33, 24, 19, 8, 19, 4, 62]\n"]},{"output_type":"stream","name":"stderr","text":[" 51%|█████     | 106/208 [00:02<00:02, 42.52it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.164783477783203\n","squlledron\n","[25, 0, 56, 22, 42, 62, 41, 4, 46, 48]\n","verogronty\n","[59, 37, 23, 62, 1, 4, 62, 63, 18, 62]\n","coduunvicl\n","[30, 46, 43, 46, 29, 63, 43, 33, 51, 42]\n","nytraverdi\n","[30, 62, 18, 4, 6, 59, 37, 23, 43, 33]\n","Canandopti\n","[30, 8, 63, 8, 63, 43, 46, 57, 19, 33]\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▌  | 156/208 [00:03<00:01, 42.31it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.093292236328125\n","richindeEt\n","[30, 61, 18, 32, 33, 63, 43, 62, 6, 18]\n","loctengich\n","[30, 62, 24, 19, 37, 63, 53, 33, 51, 32]\n","craywfuicu\n","[18, 4, 4, 62, 12, 40, 56, 23, 0, 56]\n","Eirgledory\n","[60, 37, 23, 53, 42, 62, 43, 37, 23, 62]\n","uloidodist\n","[29, 63, 46, 33, 43, 46, 43, 33, 24, 19]\n"]},{"output_type":"stream","name":"stderr","text":[" 99%|█████████▉| 206/208 [00:04<00:00, 40.64it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.73798179626465\n","slelaconge\n","[51, 39, 8, 39, 8, 18, 46, 63, 53, 37]\n","pedebtynep\n","[30, 62, 43, 8, 22, 19, 37, 63, 62, 18]\n","glasenscot\n","[60, 4, 6, 48, 8, 63, 25, 18, 46, 18]\n","somactayin\n","[25, 6, 48, 6, 24, 18, 8, 28, 61, 63]\n","duntesclma\n","[13, 29, 63, 19, 37, 24, 18, 4, 44, 8]\n"]},{"output_type":"stream","name":"stderr","text":["\r100%|██████████| 208/208 [00:04<00:00, 41.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss: 23.43073272705078\n","unermomaff\n","[29, 63, 37, 23, 55, 46, 48, 8, 7, 9]\n","========= Results: epoch 5 of 10 =========\n","train loss: 23.59| valid loss: 23.57\n","\n","========= Epoch 6 of 10 =========\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 1/208 [00:00<00:38,  5.31it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.612985610961914\n","minthablis\n","[52, 61, 63, 18, 32, 8, 22, 42, 33, 24]\n","Andersader\n","[29, 63, 43, 37, 23, 25, 6, 59, 37, 23]\n","hepenspapa\n","[35, 62, 57, 37, 63, 25, 18, 8, 51, 8]\n","Ostintryri\n","[6, 24, 19, 33, 63, 18, 4, 62, 23, 33]\n","houtotmoli\n","[30, 46, 56, 19, 37, 24, 55, 37, 42, 33]\n"]},{"output_type":"stream","name":"stderr","text":[" 28%|██▊       | 58/208 [00:01<00:03, 41.93it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.600011825561523\n","rynppaurom\n","[4, 62, 48, 57, 57, 8, 45, 4, 46, 48]\n","lstronicog\n","[4, 6, 18, 4, 46, 63, 33, 51, 46, 16]\n","soncryucse\n","[25, 46, 63, 18, 4, 62, 8, 24, 19, 37]\n","tombinprin\n","[18, 46, 20, 38, 61, 63, 18, 4, 33, 55]\n","sulaterppo\n","[25, 56, 39, 8, 19, 37, 23, 57, 57, 46]\n"]},{"output_type":"stream","name":"stderr","text":[" 52%|█████▏    | 108/208 [00:02<00:02, 42.77it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.43703842163086\n","doqusadick\n","[43, 37, 0, 56, 25, 37, 23, 33, 51, 58]\n","diargansed\n","[13, 33, 8, 23, 53, 8, 24, 25, 62, 41]\n","Gegintlich\n","[29, 63, 53, 61, 63, 53, 42, 33, 51, 32]\n","pharoerger\n","[57, 32, 8, 23, 55, 37, 23, 53, 37, 23]\n","Cricusepit\n","[60, 4, 33, 51, 56, 25, 62, 57, 61, 43]\n"]},{"output_type":"stream","name":"stderr","text":[" 76%|███████▌  | 158/208 [00:03<00:01, 42.43it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.43313980102539\n","gemellypre\n","[30, 62, 55, 8, 22, 42, 62, 57, 4, 62]\n","plyalinend\n","[60, 42, 62, 8, 22, 61, 43, 62, 63, 43]\n","waliomoybf\n","[30, 8, 22, 33, 46, 48, 46, 17, 22, 14]\n","unerstonec\n","[29, 63, 37, 23, 25, 19, 46, 48, 62, 24]\n","ciaptiviel\n","[18, 62, 6, 57, 19, 33, 43, 33, 8, 42]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 208/208 [00:05<00:00, 40.18it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.45381736755371\n","fetsinercr\n","[30, 62, 24, 19, 33, 59, 37, 23, 18, 4]\n","maingleeti\n","[30, 6, 61, 63, 53, 42, 62, 8, 19, 33]\n","callealliz\n","[51, 8, 22, 42, 62, 8, 22, 42, 33, 59]\n","ambitively\n","[6, 20, 21, 61, 19, 33, 59, 37, 42, 62]\n","stdencoaxm\n","[25, 18, 43, 37, 63, 51, 46, 29, 23, 48]\n"]},{"output_type":"stream","name":"stderr","text":["\r100%|██████████| 208/208 [00:05<00:00, 40.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss: 23.56659698486328\n","catyudemel\n","[18, 8, 19, 11, 45, 43, 62, 55, 8, 22]\n","========= Results: epoch 6 of 10 =========\n","train loss: 23.48| valid loss: 23.47\n","\n","========= Epoch 7 of 10 =========\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 1/208 [00:00<00:31,  6.67it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.229745864868164\n","unungedarr\n","[29, 63, 56, 63, 53, 37, 43, 8, 23, 57]\n","gupalddide\n","[30, 46, 57, 8, 22, 36, 13, 61, 43, 8]\n","ermospelst\n","[37, 23, 55, 8, 24, 57, 8, 39, 24, 19]\n","ofronentia\n","[6, 7, 10, 46, 48, 62, 63, 19, 33, 8]\n","avormeakia\n","[6, 59, 37, 23, 48, 62, 8, 19, 33, 8]\n"]},{"output_type":"stream","name":"stderr","text":[" 27%|██▋       | 56/208 [00:01<00:03, 44.04it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.184005737304688\n","cemiqusaon\n","[18, 8, 48, 33, 0, 56, 25, 39, 46, 48]\n","Cretinsabl\n","[60, 4, 62, 18, 61, 63, 25, 8, 22, 42]\n","grathoutit\n","[60, 4, 6, 18, 32, 46, 56, 19, 33, 43]\n","phacaexolo\n","[60, 32, 8, 51, 8, 62, 48, 46, 48, 46]\n","ledonolles\n","[30, 62, 43, 46, 48, 8, 22, 42, 62, 24]\n"]},{"output_type":"stream","name":"stderr","text":[" 51%|█████     | 106/208 [00:02<00:02, 43.36it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.463638305664062\n","dirutralle\n","[13, 61, 27, 45, 18, 4, 8, 22, 42, 62]\n","coublyetal\n","[18, 46, 56, 22, 42, 62, 8, 19, 8, 22]\n","urisserisi\n","[29, 63, 33, 24, 25, 62, 48, 33, 24, 55]\n","pyriphodde\n","[60, 2, 4, 61, 24, 32, 6, 36, 43, 37]\n","strevaguav\n","[25, 18, 4, 6, 59, 46, 1, 56, 8, 59]\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▌  | 156/208 [00:03<00:01, 41.64it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.060367584228516\n","smisterlid\n","[25, 52, 61, 24, 19, 37, 23, 42, 33, 43]\n","resmoazela\n","[4, 62, 24, 55, 46, 6, 59, 37, 23, 8]\n","ballectird\n","[21, 8, 22, 42, 62, 24, 18, 61, 23, 36]\n","Qyinatengl\n","[26, 62, 16, 43, 8, 19, 37, 63, 53, 42]\n","crosombles\n","[18, 4, 46, 48, 46, 20, 21, 42, 62, 24]\n"]},{"output_type":"stream","name":"stderr","text":[" 99%|█████████▉| 206/208 [00:04<00:00, 37.94it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.35967254638672\n","dehroidbop\n","[13, 62, 32, 10, 46, 16, 36, 31, 46, 57]\n","Ratidatong\n","[30, 8, 19, 33, 43, 8, 19, 37, 63, 53]\n","sholintlet\n","[25, 32, 46, 48, 33, 63, 19, 42, 62, 19]\n","dicatitneg\n","[13, 33, 51, 8, 19, 33, 19, 42, 62, 1]\n","Sanwerpron\n","[30, 8, 63, 12, 37, 23, 57, 4, 46, 48]\n"]},{"output_type":"stream","name":"stderr","text":["\r100%|██████████| 208/208 [00:04<00:00, 41.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss: 23.48843002319336\n","astynodrus\n","[6, 24, 19, 11, 42, 62, 41, 4, 56, 25]\n","========= Results: epoch 7 of 10 =========\n","train loss: 23.41| valid loss: 23.41\n","\n","========= Epoch 8 of 10 =========\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 1/208 [00:00<00:34,  5.97it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.19871711730957\n","cidiacaphe\n","[30, 61, 36, 33, 8, 18, 6, 57, 32, 37]\n","rapassupen\n","[4, 6, 57, 8, 24, 25, 56, 57, 37, 42]\n","veryteillo\n","[59, 37, 23, 17, 19, 37, 61, 22, 42, 62]\n","gousubsash\n","[30, 46, 56, 25, 56, 5, 25, 8, 19, 35]\n","nieandarqu\n","[30, 61, 37, 8, 63, 43, 8, 23, 0, 56]\n"]},{"output_type":"stream","name":"stderr","text":[" 27%|██▋       | 56/208 [00:01<00:03, 40.74it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.317401885986328\n","wrarcutend\n","[60, 4, 6, 23, 0, 56, 19, 37, 63, 43]\n","niflmomecl\n","[30, 61, 9, 42, 55, 46, 48, 8, 18, 4]\n","sleminteon\n","[25, 42, 62, 52, 61, 63, 19, 37, 37, 63]\n","peressqumb\n","[60, 37, 23, 62, 24, 25, 0, 56, 20, 34]\n","ponatouake\n","[57, 37, 63, 8, 19, 47, 56, 8, 58, 37]\n"]},{"output_type":"stream","name":"stderr","text":[" 51%|█████     | 106/208 [00:02<00:02, 41.79it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.511852264404297\n","usoucsanon\n","[29, 25, 0, 56, 24, 25, 8, 48, 46, 48]\n","epivanrome\n","[6, 57, 33, 59, 37, 63, 4, 46, 44, 37]\n","primbirour\n","[60, 4, 29, 20, 21, 61, 23, 0, 56, 23]\n","iVatacatym\n","[61, 59, 8, 18, 8, 19, 8, 19, 17, 48]\n","codehmalio\n","[18, 37, 43, 62, 32, 55, 8, 22, 33, 46]\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▌  | 156/208 [00:03<00:01, 42.20it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.314422607421875\n","Sonofsickh\n","[30, 6, 63, 6, 7, 19, 33, 51, 58, 32]\n","Alcoipglec\n","[29, 63, 18, 46, 29, 63, 53, 42, 62, 51]\n","scroushali\n","[25, 18, 4, 46, 56, 25, 32, 8, 22, 33]\n","tanttrOomp\n","[18, 8, 63, 19, 18, 4, 10, 46, 20, 57]\n","illyanante\n","[61, 22, 42, 62, 8, 48, 8, 63, 53, 37]\n"]},{"output_type":"stream","name":"stderr","text":[" 99%|█████████▉| 206/208 [00:04<00:00, 38.96it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 22.977214813232422\n","ritenipter\n","[4, 61, 19, 37, 63, 33, 24, 19, 37, 23]\n","sukweraste\n","[25, 56, 58, 12, 37, 23, 6, 24, 19, 37]\n","hatomirima\n","[30, 6, 53, 37, 52, 61, 23, 61, 48, 8]\n","stourtorma\n","[25, 18, 46, 56, 23, 18, 37, 23, 44, 8]\n","londerdick\n","[30, 46, 63, 43, 37, 23, 43, 33, 51, 58]\n"]},{"output_type":"stream","name":"stderr","text":["\r100%|██████████| 208/208 [00:05<00:00, 41.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss: 23.207189559936523\n","nyncheeaxw\n","[30, 11, 63, 18, 32, 37, 62, 6, 36, 12]\n","========= Results: epoch 8 of 10 =========\n","train loss: 23.34| valid loss: 23.36\n","\n","========= Epoch 9 of 10 =========\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 1/208 [00:00<00:33,  6.19it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.363895416259766\n","dmigrouang\n","[13, 52, 61, 1, 4, 46, 56, 8, 63, 53]\n","bitivierte\n","[38, 61, 19, 33, 43, 33, 37, 23, 18, 62]\n","unertumile\n","[29, 63, 37, 23, 19, 45, 52, 61, 48, 37]\n","opaeanchyo\n","[6, 57, 8, 62, 8, 63, 18, 32, 17, 62]\n","obackalleh\n","[6, 5, 8, 51, 58, 8, 22, 42, 62, 32]\n"]},{"output_type":"stream","name":"stderr","text":[" 27%|██▋       | 56/208 [00:01<00:03, 40.70it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.402938842773438\n","wareitouri\n","[12, 8, 23, 25, 61, 18, 46, 29, 23, 33]\n","wroralydle\n","[60, 10, 46, 23, 8, 22, 17, 41, 42, 62]\n","bandfuseac\n","[34, 8, 63, 43, 14, 56, 25, 62, 8, 51]\n","frearonano\n","[40, 4, 62, 8, 23, 46, 48, 8, 48, 46]\n","sushatrire\n","[25, 56, 24, 32, 8, 19, 4, 61, 27, 8]\n"]},{"output_type":"stream","name":"stderr","text":[" 51%|█████     | 106/208 [00:02<00:02, 40.61it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.531587600708008\n","ambourraim\n","[6, 20, 31, 46, 56, 23, 4, 8, 61, 20]\n","ambuitaten\n","[6, 20, 34, 56, 33, 19, 8, 19, 37, 63]\n","ditaluroes\n","[13, 61, 18, 8, 22, 56, 23, 46, 6, 24]\n","prenmistic\n","[60, 4, 8, 63, 48, 33, 24, 19, 33, 51]\n","Latledioch\n","[30, 8, 18, 42, 62, 43, 33, 46, 18, 32]\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▌  | 156/208 [00:03<00:01, 39.17it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.371824264526367\n","andorallyp\n","[29, 63, 43, 46, 48, 8, 22, 42, 11, 57]\n","Zafunvable\n","[30, 6, 7, 29, 63, 59, 8, 22, 42, 62]\n","cakornioni\n","[30, 6, 59, 37, 23, 55, 33, 46, 48, 33]\n","bophysspet\n","[30, 46, 57, 32, 17, 24, 25, 57, 61, 18]\n","spedleschu\n","[25, 57, 37, 41, 42, 62, 24, 18, 32, 56]\n"]},{"output_type":"stream","name":"stderr","text":[" 99%|█████████▉| 206/208 [00:05<00:00, 39.51it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.46151351928711\n","tlonsuppin\n","[60, 39, 46, 63, 25, 56, 57, 57, 29, 63]\n","opislsierd\n","[6, 57, 61, 25, 39, 19, 33, 8, 23, 43]\n","finlocanen\n","[40, 61, 63, 48, 46, 48, 8, 48, 62, 48]\n","vakisivelu\n","[59, 8, 58, 61, 25, 33, 59, 37, 22, 46]\n","loptbanzop\n","[4, 6, 57, 19, 31, 8, 63, 43, 46, 20]\n"]},{"output_type":"stream","name":"stderr","text":["\r100%|██████████| 208/208 [00:05<00:00, 40.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss: 23.218223571777344\n","tonomaches\n","[18, 46, 48, 46, 44, 8, 18, 35, 62, 24]\n","========= Results: epoch 9 of 10 =========\n","train loss: 23.30| valid loss: 23.32\n","\n","========= Epoch 10 of 10 =========\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 1/208 [00:00<00:33,  6.22it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.15997886657715\n","Csatiseahi\n","[60, 25, 8, 19, 33, 48, 62, 6, 32, 61]\n","Poplymbroi\n","[60, 6, 57, 42, 11, 20, 15, 4, 46, 16]\n","Lutrampeva\n","[30, 45, 19, 4, 6, 20, 57, 6, 59, 8]\n","pouknieecu\n","[60, 6, 45, 58, 48, 33, 8, 62, 0, 56]\n","BhoSentuco\n","[60, 32, 46, 25, 37, 63, 19, 45, 18, 46]\n"]},{"output_type":"stream","name":"stderr","text":[" 26%|██▋       | 55/208 [00:01<00:03, 40.50it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.393749237060547\n","cunicuging\n","[30, 45, 43, 33, 51, 56, 27, 29, 63, 53]\n","rrhesmoman\n","[18, 4, 35, 62, 24, 55, 46, 48, 8, 63]\n","grotounedr\n","[60, 4, 46, 19, 46, 29, 48, 62, 41, 4]\n","waditercol\n","[60, 8, 43, 33, 19, 37, 23, 18, 46, 48]\n","ruieperere\n","[4, 56, 61, 62, 57, 37, 23, 62, 4, 62]\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|█████     | 105/208 [00:02<00:02, 40.83it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 22.96192741394043\n","slessimiss\n","[25, 48, 62, 24, 19, 33, 52, 61, 24, 25]\n","forssupren\n","[9, 37, 23, 24, 25, 56, 60, 4, 62, 48]\n","Boneteralu\n","[30, 46, 48, 62, 18, 37, 23, 8, 42, 56]\n","endinithid\n","[29, 63, 43, 46, 48, 33, 19, 32, 61, 36]\n","loityleter\n","[30, 46, 16, 19, 11, 42, 62, 19, 37, 23]\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▍  | 155/208 [00:03<00:01, 42.13it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 23.28838539123535\n","setewaneju\n","[25, 62, 18, 62, 12, 8, 48, 62, 0, 56]\n","tymnarmoco\n","[18, 11, 20, 48, 8, 23, 55, 46, 51, 46]\n","apanglylea\n","[6, 57, 8, 63, 53, 42, 11, 42, 62, 8]\n","Binnolenca\n","[30, 29, 63, 43, 46, 48, 62, 63, 18, 6]\n","nochundest\n","[30, 46, 18, 32, 29, 63, 43, 62, 24, 19]\n"]},{"output_type":"stream","name":"stderr","text":[" 99%|█████████▊| 205/208 [00:04<00:00, 38.64it/s]"]},{"output_type":"stream","name":"stdout","text":["loss: 22.647130966186523\n","fusulmicth\n","[40, 56, 25, 56, 22, 55, 33, 24, 18, 32]\n","scelliwerc\n","[25, 18, 37, 22, 42, 62, 12, 37, 23, 18]\n","bronickult\n","[34, 10, 46, 48, 33, 51, 58, 37, 23, 18]\n","mabilmazon\n","[44, 8, 21, 61, 22, 55, 8, 59, 37, 63]\n","sadichiccc\n","[25, 6, 36, 33, 51, 32, 61, 51, 51, 19]\n"]},{"output_type":"stream","name":"stderr","text":["\r100%|██████████| 208/208 [00:05<00:00, 41.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loss: 23.05544662475586\n","dianglenno\n","[13, 33, 8, 63, 53, 42, 62, 63, 48, 46]\n","========= Results: epoch 10 of 10 =========\n","train loss: 23.25| valid loss: 23.27\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"zymBj9QrDHRM"},"source":["$N$의 다른 값을 시도하고 샘플 품질에 미치는 영향을 확인할 수 있습니다."]},{"cell_type":"code","metadata":{"id":"auBibYUTtIom","colab":{"base_uri":"https://localhost:8080/"},"outputId":"52f7c9f5-879f-4080-b49c-84fa5e2a04bb","executionInfo":{"status":"ok","timestamp":1672942523340,"user_tz":-540,"elapsed":311,"user":{"displayName":"김정인","userId":"08669711361714769540"}}},"source":["x = torch.tensor(encode(\"quack\")).unsqueeze(0)\n","T = torch.tensor([5])\n","print(model.viterbi(x,T))\n","\n","x = torch.tensor(encode(\"quick\")).unsqueeze(0)\n","T = torch.tensor([5])\n","print(model.viterbi(x,T))\n","\n","x = torch.tensor(encode(\"qurck\")).unsqueeze(0)\n","T = torch.tensor([5])\n","print(model.viterbi(x,T)) # should have lower probability---in English only vowels follow \"qu\"\n","\n","x = torch.tensor(encode(\"qiick\")).unsqueeze(0)\n","T = torch.tensor([5])\n","print(model.viterbi(x,T)) # should have lower probability---in English only \"u\" follows \"q\"\n"],"execution_count":112,"outputs":[{"output_type":"stream","name":"stdout","text":["([[0, 56, 8, 51, 58]], tensor([[-13.8923]], device='cuda:0', grad_fn=<GatherBackward0>))\n","([[0, 56, 61, 51, 58]], tensor([[-14.0026]], device='cuda:0', grad_fn=<GatherBackward0>))\n","([[0, 56, 23, 51, 58]], tensor([[-15.7310]], device='cuda:0', grad_fn=<GatherBackward0>))\n","([[0, 56, 61, 51, 58]], tensor([[-20.0309]], device='cuda:0', grad_fn=<GatherBackward0>))\n"]}]},{"cell_type":"markdown","metadata":{"id":"7eZeQXWjhDev"},"source":["## 결론\n","\n","HMM은 자연어 처리에서 매우 인기가 있는 RNN 및 트랜스포머와 신경망 모델에 의해 크게 가려졌습니다. HMM을 공부하는 것은 애매하고 긴장합니다. [Connectionist Temporal Classification](https://www.cs.toronto.edu/~graves/icml_2006.pdf)과 일반적으로 사용되는 일부 기계 학습 기술은 HMM 방법에서 영감을 받았습니다. HMM은 [여전히 인식에서 신경망과 함께 사용](https://arxiv.org/abs/1811.07453)합니다. 여기서 원-핫상태의 가정은 한 번에 하나씩 주장하는 음소에 만족합니다."]}]}